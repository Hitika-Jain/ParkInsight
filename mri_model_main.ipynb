{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hitika-Jain/ParkInsight/blob/main/mri_model_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gueWcQS6puNo",
        "outputId": "d83f1f95-8313-4b9e-e987-1bbc3bf76419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joPdsAnGqPEn"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWx11vd2o_Bs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_dicom_volume(dicom_dir):\n",
        "    \"\"\"\n",
        "    Loads and stacks DICOM slices from a given directory into a 3D volume.\n",
        "    Normalizes the volume to [0, 1].\n",
        "    \"\"\"\n",
        "    dicom_files = glob(os.path.join(dicom_dir, \"*.dcm\"))\n",
        "    slices = []\n",
        "\n",
        "    for f in dicom_files:\n",
        "        try:\n",
        "            ds = pydicom.dcmread(f)\n",
        "            slices.append(ds)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not slices:\n",
        "        return None\n",
        "\n",
        "    # Sort slices by InstanceNumber to maintain correct order\n",
        "    try:\n",
        "        slices.sort(key=lambda s: int(s.InstanceNumber))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        images = [s.pixel_array for s in slices]\n",
        "        volume = np.stack(images, axis=0).astype(np.float32)\n",
        "        # Normalize to [0, 1]\n",
        "        volume -= np.min(volume)\n",
        "        volume /= (np.max(volume) + 1e-5)\n",
        "        return volume\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def process_all_scans(root_dir, save_dir, label):\n",
        "    \"\"\"\n",
        "    Recursively processes all iso-level folders in the given root_dir,\n",
        "    converts them into 3D NumPy volumes, and saves them with global numbering.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    scan_counter = 1\n",
        "\n",
        "    for patient in tqdm(os.listdir(root_dir), desc=f\"Processing {label}\"):\n",
        "        patient_path = os.path.join(root_dir, patient)\n",
        "        if not os.path.isdir(patient_path):\n",
        "            continue\n",
        "\n",
        "        for subdir, _, _ in os.walk(patient_path):\n",
        "            dicom_files = glob(os.path.join(subdir, \"*.dcm\"))\n",
        "            if dicom_files:\n",
        "                volume = load_dicom_volume(subdir)\n",
        "                if volume is not None:\n",
        "                    filename = f\"{label}_subject{scan_counter}.npy\"\n",
        "                    save_path = os.path.join(save_dir, filename)\n",
        "                    np.save(save_path, volume)\n",
        "                    scan_counter += 1\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    pd_root = \"/content/drive/MyDrive/parkison's\"\n",
        "    hc_root = \"/content/drive/MyDrive/Health Controlled\"\n",
        "    save_path = \"/content/drive/MyDrive/3D_Numpy_Volumes\"\n",
        "\n",
        "    process_all_scans(pd_root, os.path.join(save_path, \"pd\"), label=\"pd\")\n",
        "    process_all_scans(hc_root, os.path.join(save_path, \"hc\"), label=\"hc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnCCTX0NsNV-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def count_npy_files(directory):\n",
        "    return len([f for f in os.listdir(directory) if f.endswith(\".npy\")])\n",
        "\n",
        "# Paths to your saved directories\n",
        "pd_dir = \"/content/drive/MyDrive/3D_Numpy_Volumes/pd\"\n",
        "hc_dir = \"/content/drive/MyDrive/3D_Numpy_Volumes/hc\"\n",
        "\n",
        "pd_count = count_npy_files(pd_dir)\n",
        "hc_count = count_npy_files(hc_dir)\n",
        "\n",
        "print(f\"Parkinson's scans (pd): {pd_count}\")\n",
        "print(f\"Healthy scans (hc): {hc_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74hSaAQwtAQv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "volume = np.load(\"/content/drive/MyDrive/3D_Numpy_Volumes/hc/hc_subject1.npy\")\n",
        "def show_views(slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    # Sagittal view (slice along axis=0)\n",
        "    axes[0].imshow(volume[slice_index, :, :], cmap='gray')\n",
        "    axes[0].set_title(f\"Sagittal (X={slice_index})\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Coronal view (slice along axis=1)\n",
        "    axes[1].imshow(volume[:, slice_index, :], cmap='gray')\n",
        "    axes[1].set_title(f\"Coronal (Y={slice_index})\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Axial view (slice along axis=2)\n",
        "    axes[2].imshow(volume[:, :, slice_index], cmap='gray')\n",
        "    axes[2].set_title(f\"Axial / Top-Down (Z={slice_index})\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "widgets.interact(\n",
        "    show_views,\n",
        "    slice_index=widgets.IntSlider(min=0, max=255, step=1, value=128)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iXnJqLHtXos"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "\n",
        "# Load and squeeze to ensure 3D volume\n",
        "volume = np.load(\"/content/drive/MyDrive/3D_Numpy_Volumes/pd/pd_subject1.npy\")\n",
        "volume = np.squeeze(volume)  # Ensures shape is (D, H, W)\n",
        "\n",
        "# Choose the smallest axis size as slider max\n",
        "min_dim = min(volume.shape)\n",
        "\n",
        "def show_views(slice_index):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    axes[0].imshow(volume[slice_index, :, :], cmap='gray')\n",
        "    axes[0].set_title(f\"Sagittal (X={slice_index})\")\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(volume[:, slice_index, :], cmap='gray')\n",
        "    axes[1].set_title(f\"Coronal (Y={slice_index})\")\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(volume[:, :, slice_index], cmap='gray')\n",
        "    axes[2].set_title(f\"Axial / Top-Down (Z={slice_index})\")\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "widgets.interact(\n",
        "    show_views,\n",
        "    slice_index=widgets.IntSlider(min=0, max=min_dim - 1, step=1, value=min_dim // 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpKO4rxFwDyj"
      },
      "source": [
        "Extracting the voxels from .npy files now for following regions:\n",
        "\n",
        "*   5: Left Caudate\n",
        "*   6: Left Putamen\n",
        "*   7: Left Pallidum\n",
        "*   8: Brain-Stem\n",
        "*   16: Right Caudate\n",
        "*   17: Right Putamen\n",
        "*   18: Right Pallidum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe7yaluKw1ee"
      },
      "outputs": [],
      "source": [
        "!pip install nibabel nilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6k0Xn62xDAY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from nilearn import datasets\n",
        "from nilearn.image import resample_to_img, new_img_like, math_img\n",
        "import gc  # Garbage collection\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "data_root = \"/content/drive/MyDrive/3D_Numpy_Volumes\"\n",
        "save_root = \"/content/drive/MyDrive/Extracted_Regions\"\n",
        "region_indices = [5, 6, 7, 8, 16, 17, 18]\n",
        "affine = np.array([\n",
        "    [2, 0, 0, -90],\n",
        "    [0, 2, 0, -126],\n",
        "    [0, 0, 2, -72],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "# ----------------------------------------\n",
        "\n",
        "# Load Harvard-Oxford atlas once\n",
        "atlas = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr50-1mm')\n",
        "atlas_img = atlas.maps\n",
        "atlas_labels = atlas.labels\n",
        "atlas_data = atlas_img.get_fdata()\n",
        "\n",
        "# Traverse both classes: pd and hc\n",
        "for label in ['pd', 'hc']:\n",
        "    folder_path = os.path.join(data_root, label)\n",
        "    npy_files = [f for f in os.listdir(folder_path) if f.endswith('.npy')]\n",
        "\n",
        "    for npy_file in tqdm(npy_files, desc=f\"Processing {label}\"):\n",
        "        subject_id = npy_file.replace('.npy', '')\n",
        "        npy_path = os.path.join(folder_path, npy_file)\n",
        "\n",
        "        # Load and preprocess brain array\n",
        "        brain_array = np.load(npy_path)\n",
        "        if brain_array.ndim == 4 and brain_array.shape[0] == 1:\n",
        "          brain_array = brain_array[0]\n",
        "        elif brain_array.ndim == 4:\n",
        "          raise ValueError(f\"{npy_path} has unexpected 4D shape: {brain_array.shape}\")\n",
        "\n",
        "        # Wrap into Nifti image\n",
        "        brain_img = nib.Nifti1Image(brain_array, affine)\n",
        "\n",
        "\n",
        "        # Resample to atlas space\n",
        "        resampled_brain = resample_to_img(brain_img, atlas_img, interpolation='continuous', force_resample=True)\n",
        "\n",
        "        for region_index in region_indices:\n",
        "            region_label = atlas_labels[region_index]\n",
        "            region_mask_data = (atlas_data == region_index).astype(np.uint8)\n",
        "            region_mask = new_img_like(atlas_img, region_mask_data)\n",
        "\n",
        "            # Masking\n",
        "            region_volume_img = math_img(\"img1 * img2\", img1=resampled_brain, img2=region_mask)\n",
        "            region_volume = region_volume_img.get_fdata()\n",
        "\n",
        "            if np.count_nonzero(region_volume) == 0:\n",
        "                continue\n",
        "\n",
        "            # Bounding box\n",
        "            coords = np.nonzero(region_volume)\n",
        "            zmin, zmax = np.min(coords[2]), np.max(coords[2])\n",
        "            ymin, ymax = np.min(coords[1]), np.max(coords[1])\n",
        "            xmin, xmax = np.min(coords[0]), np.max(coords[0])\n",
        "            region_crop = region_volume[xmin:xmax+1, ymin:ymax+1, zmin:zmax+1]\n",
        "\n",
        "            # Save\n",
        "            region_folder = os.path.join(save_root, f\"region_{region_index}\")\n",
        "            os.makedirs(region_folder, exist_ok=True)\n",
        "            save_path = os.path.join(region_folder, f\"{label}_{subject_id}.npy\")\n",
        "            np.save(save_path, region_crop)\n",
        "\n",
        "        # Clean up memory\n",
        "        del brain_array, brain_img, resampled_brain, region_volume_img, region_volume,\n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjuxdugKC0DM"
      },
      "source": [
        "visualization of voxels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRivzW-50Ons"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "region_paths = {\n",
        "    \"Left Caudate\": \"/content/drive/MyDrive/Extracted_Regions/region_5\",\n",
        "    \"Right Caudate\": \"/content/drive/MyDrive/Extracted_Regions/region_16\",\n",
        "    \"Left Putamen\": \"/content/drive/MyDrive/Extracted_Regions/region_6\",\n",
        "    \"Right Putamen\": \"/content/drive/MyDrive/Extracted_Regions/region_17\",\n",
        "    \"Left Pallidum\": \"/content/drive/MyDrive/Extracted_Regions/region_7\",\n",
        "    \"Right Pallidum\": \"/content/drive/MyDrive/Extracted_Regions/region_18\",\n",
        "    \"Brain-Stem\": \"/content/drive/MyDrive/Extracted_Regions/region_8\"\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, (region_name, path) in enumerate(region_paths.items()):\n",
        "    # Pick one .npy file from the region\n",
        "    sample_file = sorted(os.listdir(path))[0]\n",
        "    data = np.load(os.path.join(path, sample_file))\n",
        "\n",
        "    # Choose the middle axial slice\n",
        "    mid_slice = data.shape[2] // 2\n",
        "\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(data[:, :, mid_slice], cmap='gray')\n",
        "    plt.title(f\"{region_name}\\n{sample_file}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJNnkR1EElnB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, IntSlider\n",
        "\n",
        "# Load a single subject's region file (e.g., Brain-Stem)\n",
        "region_path = \"/content/drive/MyDrive/Extracted_Regions/region_8/hc_hc_subject1.npy\"\n",
        "data = np.load(region_path)\n",
        "\n",
        "# Viewer\n",
        "def scroll_slices(slice_idx):\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.imshow(data[:, :, slice_idx], cmap='gray')\n",
        "    plt.title(f\"Slice {slice_idx}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Slider\n",
        "interact(scroll_slices, slice_idx=IntSlider(min=0, max=data.shape[2]-1, step=1, value=data.shape[2]//2));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8U5-nAjRpff"
      },
      "source": [
        "3d vit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sosdNVNoT-FF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVn0BKCeUIe2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, regions, transform=None, target_size=(64, 64, 64)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Directory with all the brain region MRI files.\n",
        "            regions (list): List of brain region folder names.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "            target_size (tuple): The target size to resize the MRI images.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.regions = regions\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "        self.files = []\n",
        "\n",
        "        # Traverse the directory and collect all MRI files\n",
        "        for region in regions:\n",
        "            region_path = os.path.join(root_dir, region)\n",
        "            # print(f\"Checking region: {region_path}\")  # Debugging\n",
        "            for filename in os.listdir(region_path):\n",
        "                if filename.endswith('.npy'):  # Assuming .npy files\n",
        "                    # print(f\"Found file: {filename}\")  # Debugging\n",
        "                    label = 0 if filename.startswith('hc') else 1  # Label extraction based on filename prefix\n",
        "                    self.files.append((os.path.join(region_path, filename), label))\n",
        "\n",
        "        # Print the label distribution\n",
        "        # labels = [label for _, label in self.files]\n",
        "        # print(\"🧠 Dataset label distribution:\", Counter(labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.files[idx]\n",
        "        data = np.load(file_path)\n",
        "\n",
        "        # Resize the data\n",
        "        data = self.resize_volume(data, self.target_size)\n",
        "\n",
        "        # Normalize the data (standardization)\n",
        "        data = (data - np.mean(data)) / (np.std(data) + 1e-5)\n",
        "\n",
        "        # Add channel dimension\n",
        "        data = np.expand_dims(data, axis=0)  # Shape: (1, D, H, W)\n",
        "        data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "        # Optional transform\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data, label\n",
        "\n",
        "    def resize_volume(self, volume, target_size):\n",
        "        \"\"\"\n",
        "        Resize the 3D MRI volume to the target size using trilinear interpolation.\n",
        "        \"\"\"\n",
        "        volume = torch.tensor(volume).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
        "        resized = F.interpolate(volume, size=target_size, mode='trilinear', align_corners=False)\n",
        "        return resized.squeeze(0).squeeze(0).numpy()  # Remove batch and channel dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc8M6nrhgfcE"
      },
      "outputs": [],
      "source": [
        "for data, labels in dataloader:\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Label sample:\", labels[:5])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFuABp9IRrMy"
      },
      "outputs": [],
      "source": [
        "# Transformer Model Definition\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)\n",
        "\n",
        "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "        mask_value = -torch.finfo(dots.dtype).max\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value=True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, mask_value)\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out = self.to_out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout)))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask=mask)\n",
        "            x = ff(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# class ViT3D(nn.Module):\n",
        "#     MIN_NUM_PATCHES=16\n",
        "#     def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=1, dim_head=64, dropout=0., emb_dropout=0.):\n",
        "#         super().__init__()\n",
        "#         assert all([each_dimension % patch_size ==\n",
        "#                     0 for each_dimension in image_size])\n",
        "#         num_patches = (image_size[0] // patch_size) * \\\n",
        "#             (image_size[1] // patch_size)*(image_size[2] // patch_size)\n",
        "#         patch_dim = channels * patch_size ** 3\n",
        "#         assert num_patches > MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n",
        "#         assert pool in {\n",
        "#             'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "#         self.patch_size = patch_size\n",
        "\n",
        "#         self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "#         self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
        "#         self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "#         self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "#         self.transformer = Transformer(\n",
        "#             dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "#         self.pool = pool\n",
        "#         self.to_latent = nn.Identity()\n",
        "\n",
        "#         self.mlp_head = nn.Sequential(\n",
        "#             nn.LayerNorm(dim),\n",
        "#             nn.Linear(dim, num_classes)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, img, mask=None):\n",
        "#         p = self.patch_size\n",
        "\n",
        "#         # Ensure the input tensor has the correct shape: (batch, channels, depth, height, width)\n",
        "#         x = rearrange(\n",
        "#             img, 'b c (x p1) (y p2) (z p3) -> b (x y z) (p1 p2 p3 c)', p1=p, p2=p, p3=p)\n",
        "#         x = self.patch_to_embedding(x)\n",
        "#         b, n, _ = x.shape\n",
        "\n",
        "#         cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
        "#         x = torch.cat((cls_tokens, x), dim=1)\n",
        "#         x += self.pos_embedding[:, :(n + 1)]\n",
        "#         x = self.dropout(x)\n",
        "\n",
        "#         x = self.transformer(x, mask)\n",
        "\n",
        "#         x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "#         x = self.to_latent(x)\n",
        "#         return self.mlp_head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Sv0_BdbVxDe"
      },
      "outputs": [],
      "source": [
        "class ViT3D(nn.Module):\n",
        "    MIN_NUM_PATCHES = 16  # Define the minimum number of patches\n",
        "\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool='cls', channels=1, dim_head=64, dropout=0., emb_dropout=0.):\n",
        "        super().__init__()\n",
        "        assert all([each_dimension % patch_size ==\n",
        "                    0 for each_dimension in image_size])\n",
        "        num_patches = (image_size[0] // patch_size) * \\\n",
        "            (image_size[1] // patch_size)*(image_size[2] // patch_size)\n",
        "        patch_dim = channels * patch_size ** 3\n",
        "        assert num_patches > self.MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n",
        "        assert pool in {\n",
        "            'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.dropout = nn.Dropout(emb_dropout)\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            dim, depth, heads, dim_head, mlp_dim, dropout)\n",
        "\n",
        "        self.pool = pool\n",
        "        self.to_latent = nn.Identity()\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, mask=None):\n",
        "        p = self.patch_size\n",
        "\n",
        "        # Ensure the input tensor has the correct shape: (batch, channels, depth, height, width)\n",
        "        x = rearrange(\n",
        "            img, 'b c (x p1) (y p2) (z p3) -> b (x y z) (p1 p2 p3 c)', p1=p, p2=p, p3=p)\n",
        "        x = self.patch_to_embedding(x)\n",
        "        b, n, _ = x.shape\n",
        "\n",
        "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x += self.pos_embedding[:, :(n + 1)]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]\n",
        "\n",
        "        x = self.to_latent(x)\n",
        "        return self.mlp_head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gU8utnHUgP2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluation Code\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in dataloader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = loss_sum / len(dataloader)\n",
        "\n",
        "    return accuracy, avg_loss\n",
        "\n",
        "\n",
        "# Training and Evaluation Code\n",
        "def train(model, dataloader, optimizer, criterion, device, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0\n",
        "\n",
        "        for data, labels in dataloader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero gradients\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update model weights\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(dataloader)\n",
        "\n",
        "        # Evaluate after each epoch\n",
        "        accuracy, avg_loss = evaluate(model, dataloader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
        "        print(f\"Evaluation Loss: {avg_loss:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p5RHpLPYidK"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in dataloader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = loss_sum / len(dataloader)\n",
        "    return accuracy, avg_loss\n",
        "\n",
        "# Updated Training Function\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=50):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        train_loss_sum = 0\n",
        "\n",
        "        for data, labels in train_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss_sum += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_accuracy = 100 * correct_train / total_train\n",
        "        avg_train_loss = train_loss_sum / len(train_loader)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_accuracy, val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP_qJMr9Ul5_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "# Main Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset and DataLoader\n",
        "root_dir = '/content/drive/MyDrive/Extracted_Regions'  # Replace with the actual path\n",
        "regions = ['region_5','region_6','region_7','region_8','region_16','region_17','region_18']\n",
        "transform = None\n",
        "\n",
        "# dataset = BrainRegionDataset(root_dir=root_dir, regions=regions, transform=transform, target_size=(64, 64, 64))\n",
        "# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "# Initialize the model\n",
        "image_size = (64, 64, 64)  # Adjust according to your MRI scan size\n",
        "patch_size = 4\n",
        "num_classes = 2  # Healthy Control (0) or Parkinson's Disease (1)\n",
        "dim = 64\n",
        "depth = 4\n",
        "heads = 4\n",
        "mlp_dim = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ViT3D(image_size=image_size, patch_size=patch_size, num_classes=num_classes, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim).to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-vBZXC6dAqt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LightweightViT3D(nn.Module):\n",
        "    def __init__(self, image_size=64, patch_size=4, num_classes=2, dim=64, depth=4, heads=4, mlp_dim=128, dropout=0.1):\n",
        "        super(LightweightViT3D, self).__init__()\n",
        "\n",
        "        assert all(i % patch_size == 0 for i in image_size), \"Image dimensions must be divisible by patch size\"\n",
        "        num_patches_per_dim = [i // patch_size for i in image_size]\n",
        "        self.num_patches = np.prod(num_patches_per_dim)  # total number of patches\n",
        "        self.patch_dim = patch_size ** 3  # assuming one channel\n",
        "\n",
        "\n",
        "        # Patch embedding via 3D Conv\n",
        "        self.patch_embedding = nn.Conv3d(1, dim, kernel_size=patch_size, stride=patch_size)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, self.num_patches + 1, dim))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim, dropout=dropout)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
        "\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.head = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)  # (B, dim, D', H', W')\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, dim)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)  # (B, 1, dim)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embedding[:, :x.size(1), :]\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        x = self.norm(x[:, 0])  # Use CLS token\n",
        "        return self.head(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RgiMzotdFSS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "# Main Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Dataset and DataLoader\n",
        "root_dir = '/content/drive/MyDrive/Extracted_Regions'  # Replace with the actual path\n",
        "regions = ['region_5','region_6','region_7','region_8','region_16','region_17','region_18']\n",
        "transform = None\n",
        "\n",
        "# Initialize the dataset\n",
        "dataset = BrainRegionDataset(root_dir=root_dir, regions=regions, transform=transform, target_size=(64, 64, 64))\n",
        "\n",
        "# Dataset split\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader setup\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "# Initialize the model\n",
        "image_size = (64, 64, 64)  # Adjust according to your MRI scan size\n",
        "patch_size = 4\n",
        "num_classes = 2  # Healthy Control (0) or Parkinson's Disease (1)\n",
        "dim = 64\n",
        "depth = 4\n",
        "heads = 4\n",
        "mlp_dim = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LightweightViT3D(image_size=image_size, patch_size=patch_size, num_classes=num_classes, dim=dim, depth=depth, heads=heads, mlp_dim=mlp_dim).to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg5gh1X7ekH-"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# example:\n",
        "weights = compute_class_weight('balanced', classes=[0,1], y=labels)\n",
        "# then use in loss:\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights).float().to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUhxFwMRfY36"
      },
      "source": [
        "3d cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f82JfELkfaUw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Dataset class\n",
        "class MultiRegionVoxelDataset(Dataset):\n",
        "    def __init__(self, region_dirs):\n",
        "        self.file_paths = []\n",
        "        for region in region_dirs:\n",
        "            files = [f for f in os.listdir(region) if f.endswith('.npy')]\n",
        "            self.file_paths += [os.path.join(region, f) for f in files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      path = self.file_paths[idx]\n",
        "      voxel = np.load(path)\n",
        "\n",
        "      # Get current shape\n",
        "      x, y, z = voxel.shape\n",
        "\n",
        "      # Crop if too big\n",
        "      voxel = voxel[:64, :64, :64]\n",
        "\n",
        "      # Pad if too small\n",
        "      padded = np.zeros((64, 64, 64), dtype=np.float32)\n",
        "      padded[:voxel.shape[0], :voxel.shape[1], :voxel.shape[2]] = voxel\n",
        "      voxel = padded\n",
        "\n",
        "      voxel = torch.tensor(voxel).unsqueeze(0)  # Add channel dim\n",
        "\n",
        "      label = 0 if os.path.basename(path).startswith('hc') else 1\n",
        "      return voxel, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6D1Mu0_gAKf"
      },
      "outputs": [],
      "source": [
        "region_folders = [\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_5',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_6',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_7',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_8',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_16',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_17',\n",
        "    '/content/drive/MyDrive/Extracted_Regions/region_18',\n",
        "]\n",
        "\n",
        "dataset = MultiRegionVoxelDataset(region_folders)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fon1Zk9ffeiW"
      },
      "outputs": [],
      "source": [
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool3d(2)\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # [16, 32, 32, 32]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # [32, 16, 16, 16]\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # [64, 8, 8, 8]\n",
        "        x = x.view(x.size(0), -1)             # flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VlQ3gGhfjNb"
      },
      "outputs": [],
      "source": [
        "def train_eval(model, dataloader, optimizer, criterion, device, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            loss = criterion(output, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(dataloader)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct, total, eval_loss = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in dataloader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                output = model(x)\n",
        "                loss = criterion(output, y)\n",
        "                eval_loss += loss.item()\n",
        "                pred = output.argmax(dim=1)\n",
        "                correct += (pred == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        eval_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Eval Acc: {eval_acc:.2f}% | Eval Loss: {eval_loss / len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vVI6BgRfnae"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Root folder where all region folders are stored\n",
        "root_dir = '/content/drive/MyDrive/Extracted_Regions'\n",
        "\n",
        "# Automatically collect full paths of all subfolders inside root_dir\n",
        "region_folders = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "\n",
        "# Now pass this list to the dataset\n",
        "dataset = MultiRegionVoxelDataset(region_folders)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "model = Simple3DCNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_eval(model, dataloader, optimizer, criterion, device, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liCxU_19SpPE"
      },
      "outputs": [],
      "source": [
        "class Lightweight3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lightweight3DCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1),  # (B, 16, 64, 64, 64)\n",
        "            nn.BatchNorm3d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(2),  # (B, 16, 32, 32, 32)\n",
        "\n",
        "            nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1),  # (B, 32, 32, 32, 32)\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(2),  # (B, 32, 16, 16, 16)\n",
        "\n",
        "            nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1),  # (B, 64, 16, 16, 16)\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool3d((4, 4, 4))  # (B, 64, 4, 4, 4)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),  # (B, 64*4*4*4)\n",
        "            nn.Linear(64 * 4 * 4 * 4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6L5FMmmStL5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Root folder where all region folders are stored\n",
        "root_dir = '/content/drive/MyDrive/Extracted_Regions'\n",
        "\n",
        "# Automatically collect full paths of all subfolders inside root_dir\n",
        "region_folders = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "\n",
        "# Now pass this list to the dataset\n",
        "dataset = MultiRegionVoxelDataset(region_folders)\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "model = Lightweight3DCNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_eval(model, dataloader, optimizer, criterion, device, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvO7JCRQX6v2"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# After loading your dataset\n",
        "labels = [int(f.split('_')[-1].split('.')[0]) for f in all_file_names]\n",
        "weights = compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
        "weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KKhACUML9Qs"
      },
      "source": [
        "#3d resnet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfBLdkHbMawf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_qCt6q7QV-o"
      },
      "outputs": [],
      "source": [
        "# ✅ RUN THIS ONCE to preprocess and save resized volumes\n",
        "def resize_volume(volume, target_shape=(64, 64, 64)):\n",
        "    tensor = torch.tensor(volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]\n",
        "    resized = F.interpolate(tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
        "    return resized.squeeze().numpy()\n",
        "\n",
        "input_root = \"/content/drive/MyDrive/Extracted_Regions\"\n",
        "output_root = \"/content/drive/MyDrive/Resized_Regions\"\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "region_names = ['region_5', 'region_6', 'region_7', 'region_8', 'region_16', 'region_17', 'region_18']\n",
        "\n",
        "for region in region_names:\n",
        "    in_path = os.path.join(input_root, region)\n",
        "    out_path = os.path.join(output_root, region)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    for fname in os.listdir(in_path):\n",
        "        if fname.endswith(\".npy\"):\n",
        "            vol = np.load(os.path.join(in_path, fname))\n",
        "            resized = resize_volume(vol)\n",
        "            np.save(os.path.join(out_path, fname), resized)\n",
        "\n",
        "print(\"✅ Preprocessing done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Exn4C7KsRXfJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Subset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# You can add transformations like random rotations and flips\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "])\n",
        "\n",
        "# Add it to your dataset:\n",
        "class MultiRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, region_names, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.region_names = region_names\n",
        "        self.transform = transform\n",
        "        self.samples = self._collect_samples()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        regions = []\n",
        "        for region in self.region_names:\n",
        "            path = os.path.join(self.root_dir, region, sample[\"name\"])\n",
        "            vol = np.load(path)\n",
        "            vol_tensor = torch.tensor(vol, dtype=torch.float32).unsqueeze(0)  # [1, D, H, W]\n",
        "            regions.append(vol_tensor)\n",
        "        x = torch.stack(regions)  # [R, 1, D, H, W]\n",
        "        label = 0 if name.startswith('hc') else 1\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, label\n",
        "\n",
        "# Dataset\n",
        "# class MultiRegionDataset(Dataset):\n",
        "#     def __init__(self, root_dir, region_names):\n",
        "#         self.root_dir = root_dir\n",
        "#         self.region_names = region_names\n",
        "#         self.samples = self._collect_samples()\n",
        "\n",
        "#     def _collect_samples(self):\n",
        "#         sample_names = os.listdir(os.path.join(self.root_dir, self.region_names[0]))\n",
        "#         samples = []\n",
        "#         for name in sample_names:\n",
        "#             if name.endswith(\".npy\"):\n",
        "#                 label = 0 if name.startswith('hc') else 1\n",
        "#                 samples.append({\"name\": name, \"label\": label})\n",
        "#         return samples\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.samples)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         sample = self.samples[idx]\n",
        "#         regions = []\n",
        "#         for region in self.region_names:\n",
        "#             path = os.path.join(self.root_dir, region, sample[\"name\"])\n",
        "#             vol = np.load(path)\n",
        "#             vol_tensor = torch.tensor(vol, dtype=torch.float32).unsqueeze(0)  # [1, D, H, W]\n",
        "#             regions.append(vol_tensor)\n",
        "#         x = torch.stack(regions)  # [R, 1, D, H, W]\n",
        "#         label = torch.tensor(sample[\"label\"], dtype=torch.long)\n",
        "#         return x, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soCEfjGCMDKk"
      },
      "outputs": [],
      "source": [
        "# Basic 3D ResNet block\n",
        "class BasicBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
        "        self.skip = nn.Conv3d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.skip(x)\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        return self.relu(x + identity)\n",
        "\n",
        "# Small ResNet Model for each region\n",
        "class RegionResNet3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.block1 = BasicBlock3D(1, 16)\n",
        "        self.block2 = BasicBlock3D(16, 32)\n",
        "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return x  # shape: [B, 32]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PsoS2g4M550"
      },
      "outputs": [],
      "source": [
        "# Main Ensemble Model\n",
        "class MultiRegionResNetEnsemble(nn.Module):\n",
        "    def __init__(self, num_regions):\n",
        "        super().__init__()\n",
        "        self.region_models = nn.ModuleList([RegionResNet3D() for _ in range(num_regions)])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32 * num_regions, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [self.region_models[i](x[:, i]) for i in range(x.size(1))]\n",
        "        combined = torch.cat(features, dim=1)\n",
        "        return self.classifier(combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d06nREZJM-7F"
      },
      "outputs": [],
      "source": [
        "# Training & Eval\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(loader.dataset), correct / len(loader.dataset)\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(loader.dataset), correct / len(loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySaInC3ANC9-"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "region_names = ['region_5', 'region_6', 'region_7', 'region_8', 'region_16', 'region_17', 'region_18']\n",
        "dataset = MultiRegionDataset(\"/content/drive/MyDrive/Resized_Regions\", region_names)\n",
        "\n",
        "# Split\n",
        "indices = list(range(len(dataset)))\n",
        "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(Subset(dataset, train_idx), batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(Subset(dataset, val_idx), batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Model\n",
        "model = MultiRegionResNetEnsemble(num_regions=len(region_names)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Lower learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Acc: {train_acc*100:.2f}% | Val Loss: {val_loss:.4f} | Acc: {val_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQPpIPWFYcUx"
      },
      "source": [
        "deeper resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlgl2ooCZT6K"
      },
      "outputs": [],
      "source": [
        "pip install torchio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7uUWZoOZx8O"
      },
      "outputs": [],
      "source": [
        "import torchio as tio\n",
        "\n",
        "transform = tio.Compose([\n",
        "    tio.RandomFlip(axes=(0, 1, 2)),\n",
        "    tio.RandomAffine(scales=0.1, degrees=10),\n",
        "    tio.RandomNoise(mean=0, std=0.01),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vmNzfw-ZOyT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MultiRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, region_names):\n",
        "        self.region_names = region_names\n",
        "        self.root_dir = root_dir\n",
        "        self.data = {region: [] for region in region_names}\n",
        "        self.labels = []\n",
        "\n",
        "        # Assume all regions have same filenames, just in their respective folders\n",
        "        filenames = sorted(os.listdir(os.path.join(root_dir, region_names[0])))\n",
        "\n",
        "        for file in filenames:\n",
        "            if not file.endswith(\".npy\"):\n",
        "                continue\n",
        "\n",
        "            # Label from filename\n",
        "            if file.startswith(\"hc_hc\"):\n",
        "                label = 0\n",
        "            elif file.startswith(\"pd_pd\"):\n",
        "                label = 1\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown label prefix in file: {file}\")\n",
        "\n",
        "            self.labels.append(label)\n",
        "\n",
        "            for region in region_names:\n",
        "                full_path = os.path.join(root_dir, region, file)\n",
        "                self.data[region].append(full_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = []\n",
        "        for region in self.region_names:\n",
        "            arr = np.load(self.data[region][idx])\n",
        "            arr = torch.tensor(arr, dtype=torch.float32).unsqueeze(0)  # Shape: [1, D, H, W]\n",
        "            sample.append(arr)\n",
        "        x = torch.cat(sample, dim=0)  # Shape: [num_regions, D, H, W]\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDMTAWruTkGA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MultiRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, region_names):\n",
        "        self.region_names = region_names\n",
        "        self.root_dir = root_dir\n",
        "        self.data = {region: [] for region in region_names}\n",
        "        self.labels = []\n",
        "\n",
        "        # Assume all regions have same filenames, just in their respective folders\n",
        "        filenames = sorted(os.listdir(os.path.join(root_dir, region_names[0])))\n",
        "\n",
        "        for file in filenames:\n",
        "            if not file.endswith(\".npy\"):\n",
        "                continue\n",
        "\n",
        "            # Label from filename\n",
        "            if file.startswith(\"hc_hc\"):\n",
        "                label = 0\n",
        "            elif file.startswith(\"pd_pd\"):\n",
        "                label = 1\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown label prefix in file: {file}\")\n",
        "\n",
        "            self.labels.append(label)\n",
        "\n",
        "            for region in region_names:\n",
        "                full_path = os.path.join(root_dir, region, file)\n",
        "                self.data[region].append(full_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = []\n",
        "        for region in self.region_names:\n",
        "            arr = np.load(self.data[region][idx])\n",
        "            arr = torch.tensor(arr, dtype=torch.float32).unsqueeze(0)  # Shape: [1, D, H, W]\n",
        "            sample.append(arr)\n",
        "        x = torch.cat(sample, dim=0)  # Shape: [num_regions, D, H, W]\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK4x3AMVYaBZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# -------------------------------\n",
        "# 3D Basic Residual Block\n",
        "# -------------------------------\n",
        "class BasicBlock3D(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock3D, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# -------------------------------\n",
        "# 3D ResNet Architecture\n",
        "# -------------------------------\n",
        "class ResNet3D(nn.Module):\n",
        "    def __init__(self, block, layers, in_channels=1, num_classes=2):\n",
        "        super(ResNet3D, self).__init__()\n",
        "        self.inplanes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        self.apply(self._weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv3d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _weights_init(self, m):\n",
        "        if isinstance(m, nn.Conv3d):\n",
        "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        elif isinstance(m, nn.BatchNorm3d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc-cGprCZEeU"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFa-L-j-ZJU8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# If using a single-region dataset like Brainstem only:\n",
        "# region_names = ['region_5','region_6','region_7','region_8','region_16','region_17','region_18']  # or any one region, since you're not using ensemble now\n",
        "region_names = ['region_8']\n",
        "dataset = MultiRegionDataset(\"/content/drive/MyDrive/Resized_Regions\", region_names)\n",
        "\n",
        "# Split\n",
        "indices = list(range(len(dataset)))\n",
        "train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(Subset(dataset, train_idx), batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(Subset(dataset, val_idx), batch_size=4, shuffle=False, num_workers=2)\n",
        "for x, y in train_loader:\n",
        "    print(x.shape)  # Should be [batch_size, channels, D, H, W]\n",
        "    break\n",
        "# Model\n",
        "def resnet18_3d(in_channels=1, num_classes=2):\n",
        "    return ResNet3D(BasicBlock3D, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
        "# Example: Single region\n",
        "# Create model instance\n",
        "model = resnet18_3d(in_channels=1, num_classes=2)\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Print model summary (optional)\n",
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 64, 64, 64))  # assuming single-channel 64³ input\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.unsqueeze(1)  # inputs is a tuple of 1 tensor (since len(region_names) = 1)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    acc = correct / len(dataloader.dataset)\n",
        "    return avg_loss, acc\n",
        "\n",
        "# Evaluation loop\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs[0].to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader.dataset)\n",
        "    acc = correct / len(dataloader.dataset)\n",
        "    return avg_loss, acc\n",
        "\n",
        "# Train\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Acc: {train_acc*100:.2f}% | Val Loss: {val_loss:.4f} | Acc: {val_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA-IlmCGsxc7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op56natQYhPK"
      },
      "source": [
        "#2d resnet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPAT3lOJYkBx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MultiSlice2DDataset(Dataset):\n",
        "    def __init__(self, root_dir, num_slices=5, max_files_per_class=20):\n",
        "        self.samples = []\n",
        "        self.num_slices = num_slices\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),  # Converts to [C, H, W] (assuming single channel)\n",
        "            transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "        ])\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')][:max_files_per_class]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')][:max_files_per_class]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))\n",
        "\n",
        "        self.slice_samples = []\n",
        "        for file_path, label in self.samples:\n",
        "            volume = np.load(file_path)\n",
        "            mid = volume.shape[0] // 2\n",
        "            half = num_slices // 2\n",
        "            selected_slices = range(mid - half, mid + half + 1)\n",
        "            for slice_idx in selected_slices:\n",
        "                if 0 <= slice_idx < volume.shape[0]:\n",
        "                    self.slice_samples.append((file_path, slice_idx, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, slice_idx, label = self.slice_samples[idx]\n",
        "        volume = np.load(file_path)\n",
        "        slice_2d = volume[slice_idx]\n",
        "\n",
        "        # Normalize the slice between 0 and 1\n",
        "        slice_2d = (slice_2d - np.min(slice_2d)) / (np.max(slice_2d) - np.min(slice_2d) + 1e-8)\n",
        "\n",
        "        # Convert the 2D numpy slice to a PIL image for transformation\n",
        "        slice_2d_pil = Image.fromarray(slice_2d)\n",
        "\n",
        "        # Apply transformations\n",
        "        slice_2d = self.transform(slice_2d_pil)  # [1, 224, 224]\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "        return slice_2d, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D17d_3uoY2ov"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_resnet18_2d():\n",
        "    model = models.resnet18(pretrained=False)\n",
        "\n",
        "    # Modify the first convolution layer to accept 1-channel (grayscale) input\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # Modify the final fully connected layer to output 2 classes for binary classification\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9pFKiFNY7zz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load dataset\n",
        "dataset = MultiSlice2DDataset('/content/drive/MyDrive/3D_Numpy_Volumes')\n",
        "train_len = int(0.8 * len(dataset))\n",
        "val_len = len(dataset) - train_len\n",
        "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = get_resnet18_2d().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "def train(model, dataloader):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)\n",
        "\n",
        "# Evaluation loop\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)\n",
        "\n",
        "# Run training\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc = train(model, train_loader)\n",
        "    val_loss, val_acc = evaluate(model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc*100:.2f}% | Val Loss={val_loss:.4f}, Acc={val_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klCskSP6clJc"
      },
      "source": [
        "#3d mid brain region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMt-I0GVcn8W"
      },
      "outputs": [],
      "source": [
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)\n",
        "\n",
        "        # Step 2: Extract 3D midbrain region\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        # Ensure midbrain_region is 3D (if it has a single channel, don't squeeze it)\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        # Step 3: Resize the extracted region to a fixed size\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        # Step 4: Normalize and apply transformations\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)  # Normalize to [0, 1]\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)  # Add channel dimension (1, 64, 64, 64)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "        return resized_region, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Fn_oelczfL"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define the 3D ResNet model\n",
        "class ResNet3D(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ResNet3D, self).__init__()\n",
        "        model = models.resnet18(pretrained=False)\n",
        "        model.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 3D convolution\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HviZoxJlc28s"
      },
      "outputs": [],
      "source": [
        "# Step 3: Define the 3D ViT model\n",
        "class ViT3D(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(ViT3D, self).__init__()\n",
        "        # You can implement a 3D Vision Transformer model here or use a pre-existing one\n",
        "        # You may need a library like `timm` for ViT models if available\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implement the forward pass for 3D Vision Transformer\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWsY32pMc721"
      },
      "outputs": [],
      "source": [
        "# Step 4: Train and evaluate the model\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            correct += (out.argmax(1) == y).sum().item()\n",
        "    return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty1CQj8mdB0l"
      },
      "outputs": [],
      "source": [
        "# Step 5: Set up data loaders and training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "root_dir = \"/content/drive/MyDrive/3D_Numpy_Volumes\"  # Replace with your dataset path\n",
        "midbrain_center = (100, 120, 150)  # Replace with actual center coordinates of the midbrain\n",
        "transform = transforms.Compose([transforms.Resize((64, 64))])\n",
        "\n",
        "# Initialize dataset and dataloaders\n",
        "dataset = BrainRegionDataset(root_dir, midbrain_center, region_size=(30, 30, 30), transform=transform)\n",
        "train_len = int(0.8 * len(dataset))\n",
        "val_len = len(dataset) - train_len\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "model = ResNet3D(num_classes=2).to(device)  # Change to ViT3D(num_classes=2) if using ViT\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Step 6: Training and evaluation loop\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc*100:.2f}% | Val Loss={val_loss:.4f}, Acc={val_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asWp_A0NdxfM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy.ndimage\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy.ndimage\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        # Extract a 3D region based on the given center and size\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        # Step 1: Ensure volume is 3D (if it's 4D, remove the channel dimension)\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present (e.g., shape: (1, d, h, w) -> (d, h, w))\n",
        "\n",
        "        # Step 2: Extract 3D midbrain region (ensure it's 3D)\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        # Ensure midbrain_region is 3D (should not be 4D)\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        # Step 3: Resize the extracted region to a fixed size (64x64x64)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        # Ensure resized_region is 3D after resizing\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        # Step 4: Normalize to range [0, 1]\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)  # Normalize to [0, 1]\n",
        "\n",
        "        # Step 5: Add channel dimension (1, 64, 64, 64)\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)  # Add the channel dimension\n",
        "\n",
        "        # Apply any additional transformations (e.g., data augmentation)\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "# Modify the first convolution layer of the model to accept 1 input channel\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        # Access and modify the first convolution layer (conv1) inside the BasicStem\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Load a pre-trained 3D ResNet model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "\n",
        "# Move the model to the appropriate device (e.g., CUDA if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize dataset and dataloaders\n",
        "# Initialize your dataset\n",
        "root_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "train_set = BrainRegionDataset(root_dir=root_dir, midbrain_center=(64, 64, 64))\n",
        "\n",
        "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
        "train_indices, val_indices = train_test_split(range(len(train_set)), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create training and validation subsets using the indices\n",
        "train_subset = Subset(train_set, train_indices)\n",
        "val_subset = Subset(train_set, val_indices)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 4\n",
        "\n",
        "# Create data loaders for training and validation\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the dataset sizes\n",
        "print(f\"Training set size: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation set size: {len(val_loader.dataset)}\")\n",
        "\n",
        "# Training loop\n",
        "# def train(model, dataloader, criterion, optimizer, device):\n",
        "#     model.train()\n",
        "#     total_loss, correct = 0, 0\n",
        "#     for x, y in dataloader:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         out = model(x)\n",
        "#         loss = criterion(out, y)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         total_loss += loss.item() * y.size(0)\n",
        "#         correct += (out.argmax(1) == y).sum().item()\n",
        "#     return total_loss / len(dataloader.dataset), correct / len(dataloader.dataset)\n",
        "\n",
        "# # Run training\n",
        "# for epoch in range(20):\n",
        "#     train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "#     print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Acc={train_acc*100:.2f}%\")\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0.0, 0\n",
        "        train_total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        val_loss, val_correct = 0.0, 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():  # Disable gradient calculation for validation\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_accuracy = val_correct / val_total\n",
        "\n",
        "        # Print metrics for this epoch\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
        "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awJ3ZazMqQ0W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy.ndimage\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import scipy.ndimage\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        # Extract a 3D region based on the given center and size\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        # Step 1: Ensure volume is 3D (if it's 4D, remove the channel dimension)\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present (e.g., shape: (1, d, h, w) -> (d, h, w))\n",
        "\n",
        "        # Step 2: Extract 3D midbrain region (ensure it's 3D)\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        # Ensure midbrain_region is 3D (should not be 4D)\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        # Step 3: Resize the extracted region to a fixed size (64x64x64)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        # Ensure resized_region is 3D after resizing\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        # Step 4: Normalize to range [0, 1]\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)  # Normalize to [0, 1]\n",
        "\n",
        "        # Step 5: Add channel dimension (1, 64, 64, 64)\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)  # Add the channel dimension\n",
        "\n",
        "        # Apply any additional transformations (e.g., data augmentation)\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "# Modify the first convolution layer of the model to accept 1 input channel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Modify the first convolution layer (conv1) to use Conv3d\n",
        "        original_model.conv1 = nn.Conv3d(1, original_model.conv1.out_channels,\n",
        "                                         kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
        "\n",
        "        # Modify the max pooling layer to handle 3D input\n",
        "        original_model.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "\n",
        "        # Replace BatchNorm2d with BatchNorm3d for all batchnorm layers in the model\n",
        "        for name, module in original_model.named_modules():\n",
        "            if isinstance(module, nn.BatchNorm2d):\n",
        "                in_channels = module.num_features\n",
        "                # Create a new BatchNorm3d and assign it\n",
        "                batch_norm_3d = nn.BatchNorm3d(in_channels)\n",
        "                setattr(original_model, name, batch_norm_3d)\n",
        "\n",
        "        # Now assign the model\n",
        "        self.model = original_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Move the model to the appropriate device (e.g., CUDA if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adding weight decay\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize dataset and dataloaders\n",
        "# Initialize your dataset\n",
        "root_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "train_set = BrainRegionDataset(root_dir=root_dir, midbrain_center=(64, 64, 64))\n",
        "\n",
        "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
        "train_indices, val_indices = train_test_split(range(len(train_set)), test_size=0.2, random_state=42)\n",
        "\n",
        "# Create training and validation subsets using the indices\n",
        "train_subset = Subset(train_set, train_indices)\n",
        "val_subset = Subset(train_set, val_indices)\n",
        "\n",
        "# Define the batch size\n",
        "batch_size = 4\n",
        "\n",
        "# Create data loaders for training and validation\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the dataset sizes\n",
        "print(f\"Training set size: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation set size: {len(val_loader.dataset)}\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.models import resnet50  # Example of using ResNet50, you can choose others like resnet101\n",
        "\n",
        "# Assuming BrainRegionDataset is your custom dataset\n",
        "# Assuming CustomResNet3D is your modified model class\n",
        "\n",
        "def k_fold_validation(model_class, dataset, k=5, num_epochs=20, batch_size=4, device='cuda'):\n",
        "    kfold = KFold(n_splits=k, shuffle=True)\n",
        "\n",
        "    # Prepare an array to store results\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold + 1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subsampler = Subset(dataset, train_idx)\n",
        "        val_subsampler = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoaders for train and validation sets\n",
        "        train_loader = DataLoader(train_subsampler, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_subsampler, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        # Initialize model\n",
        "        original_model = resnet50(pretrained=True)  # You can use resnet34, resnet101, resnet152, etc.\n",
        "        model = model_class(original_model).to(device)  # Custom ResNet3D model\n",
        "\n",
        "        # Loss function and optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()  # Set the model to training mode\n",
        "            train_loss, train_correct = 0.0, 0\n",
        "            train_total = 0\n",
        "\n",
        "            # Training phase\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "            # Calculate training metrics\n",
        "            train_loss /= train_total\n",
        "            train_accuracy = train_correct / train_total\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()  # Set the model to evaluation mode\n",
        "            val_loss, val_correct = 0.0, 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():  # Disable gradient calculation during validation\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "            # Calculate validation metrics\n",
        "            val_loss /= val_total\n",
        "            val_accuracy = val_correct / val_total\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
        "                  f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "        # Store the accuracy for each fold\n",
        "        fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Calculate average validation accuracy across all folds\n",
        "    avg_accuracy = sum(fold_accuracies) / k\n",
        "    print(f\"Average Validation Accuracy across {k} folds: {avg_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Example usage\n",
        "k_fold_validation(CustomResNet3D, train_set, k=5, num_epochs=20, batch_size=4, device='cuda')\n",
        "\n",
        "# def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20):\n",
        "#     for epoch in range(num_epochs):\n",
        "#         # Training phase\n",
        "#         model.train()\n",
        "#         train_loss, train_correct = 0.0, 0\n",
        "#         train_total = 0\n",
        "#         for inputs, labels in train_loader:\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#             train_loss += loss.item() * inputs.size(0)\n",
        "#             _, predicted = torch.max(outputs, 1)\n",
        "#             train_correct += (predicted == labels).sum().item()\n",
        "#             train_total += labels.size(0)\n",
        "\n",
        "#         train_loss /= train_total\n",
        "#         train_accuracy = train_correct / train_total\n",
        "\n",
        "#         # Validation phase\n",
        "#         model.eval()  # Set the model to evaluation mode\n",
        "#         val_loss, val_correct = 0.0, 0\n",
        "#         val_total = 0\n",
        "#         with torch.no_grad():  # Disable gradient calculation for validation\n",
        "#             for inputs, labels in val_loader:\n",
        "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "#                 outputs = model(inputs)\n",
        "#                 loss = criterion(outputs, labels)\n",
        "\n",
        "#                 val_loss += loss.item() * inputs.size(0)\n",
        "#                 _, predicted = torch.max(outputs, 1)\n",
        "#                 val_correct += (predicted == labels).sum().item()\n",
        "#                 val_total += labels.size(0)\n",
        "\n",
        "#         val_loss /= val_total\n",
        "#         val_accuracy = val_correct / val_total\n",
        "\n",
        "#         # Print metrics for this epoch\n",
        "#         print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "#               f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
        "#               f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "# train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7XqS7jpuAIo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Dataset class\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        # Extract a 3D region based on the given center and size\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        # Ensure volume is 3D (if it's 4D, remove the channel dimension)\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present (e.g., shape: (1, d, h, w) -> (d, h, w))\n",
        "\n",
        "        # Extract 3D midbrain region\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        # Resize the extracted region to a fixed size (64x64x64)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        # Normalize to range [0, 1]\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        # Add channel dimension (1, 64, 64, 64)\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)  # Add the channel dimension\n",
        "\n",
        "        # Apply any additional transformations (e.g., data augmentation)\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# Custom ResNet3D Model Class\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Modify the first convolution layer (conv1) to use Conv3d\n",
        "        self.conv1 = nn.Conv3d(1, original_model.conv1.out_channels,\n",
        "                               kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
        "\n",
        "        # BatchNorm3d should now expect 5D input (batch_size, channels, depth, height, width)\n",
        "        self.bn1 = original_model.bn1\n",
        "        self.relu = original_model.relu\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "\n",
        "        # Rest of the layers\n",
        "        self.layer1 = original_model.layer1\n",
        "        self.layer2 = original_model.layer2\n",
        "        self.layer3 = original_model.layer3\n",
        "        self.layer4 = original_model.layer4\n",
        "\n",
        "        # Final fully connected layer\n",
        "        self.fc = original_model.fc\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Ensure the input is 5D: (batch_size, 1, depth, height, width)\n",
        "        # Conv3D and BatchNorm3D expect this shape\n",
        "        x = self.conv1(x)  # (batch_size, channels, depth, height, width)\n",
        "        x = self.bn1(x)  # (batch_size, channels, depth, height, width)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Example usage:\n",
        "# Load ResNet50 with pre-trained weights\n",
        "original_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "# Create the custom 3D model\n",
        "model = CustomResNet3D(original_model).to('cuda')  # Move to device (e.g., 'cuda')\n",
        "\n",
        "# Check the model\n",
        "print(model)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adding weight decay\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Dataset initialization\n",
        "root_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "train_set = BrainRegionDataset(root_dir=root_dir, midbrain_center=(64, 64, 64))\n",
        "\n",
        "# Split dataset into training and validation sets (80% train, 20% validation)\n",
        "train_indices, val_indices = train_test_split(range(len(train_set)), test_size=0.2, random_state=42)\n",
        "train_subset = Subset(train_set, train_indices)\n",
        "val_subset = Subset(train_set, val_indices)\n",
        "\n",
        "# DataLoader initialization\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the dataset sizes\n",
        "print(f\"Training set size: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation set size: {len(val_loader.dataset)}\")\n",
        "\n",
        "# Training loop\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss, train_correct = 0.0, 0\n",
        "        train_total = 0\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "        train_loss /= train_total\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss, val_correct = 0.0, 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_loss /= val_total\n",
        "        val_accuracy = val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
        "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V97ue2Oxwmjy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        # Extract a 3D region based on the given center and size\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        # Step 1: Ensure volume is 3D (if it's 4D, remove the channel dimension)\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present (e.g., shape: (1, d, h, w) -> (d, h, w))\n",
        "\n",
        "        # Step 2: Extract 3D midbrain region (ensure it's 3D)\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        # Ensure midbrain_region is 3D (should not be 4D)\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        # Step 3: Resize the extracted region to a fixed size (64x64x64)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        # Ensure resized_region is 3D after resizing\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        # Step 4: Normalize to range [0, 1]\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)  # Normalize to [0, 1]\n",
        "\n",
        "        # Step 5: Add channel dimension (1, 64, 64, 64)\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)  # Add the channel dimension\n",
        "\n",
        "        # Apply any additional transformations (e.g., data augmentation)\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "# Modify the first convolution layer of the model to accept 1 input channel\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        # Access and modify the first convolution layer (conv1) inside the BasicStem\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Load a pre-trained 3D ResNet model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "\n",
        "# Move the model to the appropriate device (e.g., CUDA if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoader for training and validation\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = model_class(original_model)\n",
        "        model.to(device)\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss, train_correct = 0.0, 0\n",
        "            train_total = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "            train_loss /= train_total\n",
        "            train_accuracy = train_correct / train_total\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss, val_correct = 0.0, 0\n",
        "            val_total = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "            val_loss /= val_total\n",
        "            val_accuracy = val_correct / val_total\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy*100:.2f}%, \"\n",
        "                  f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "        results.append((train_loss, train_accuracy, val_loss, val_accuracy))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run K-Fold cross-validation\n",
        "k = 5\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=20)\n",
        "print(\"K-Fold Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhhxcKqIddua"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoader for training and validation\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = model_class(original_model)\n",
        "        model.to(device)\n",
        "\n",
        "        # Initialize accumulators for metrics\n",
        "        total_train_loss, total_train_correct = 0.0, 0\n",
        "        total_train_samples = 0\n",
        "        total_val_loss, total_val_correct = 0.0, 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            epoch_train_loss, epoch_train_correct = 0.0, 0\n",
        "            epoch_train_samples = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                epoch_train_correct += (predicted == labels).sum().item()\n",
        "                epoch_train_samples += labels.size(0)\n",
        "\n",
        "            total_train_loss += epoch_train_loss\n",
        "            total_train_correct += epoch_train_correct\n",
        "            total_train_samples += epoch_train_samples\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            epoch_val_loss, epoch_val_correct = 0.0, 0\n",
        "            epoch_val_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    epoch_val_correct += (predicted == labels).sum().item()\n",
        "                    epoch_val_samples += labels.size(0)\n",
        "\n",
        "            total_val_loss += epoch_val_loss\n",
        "            total_val_correct += epoch_val_correct\n",
        "            total_val_samples += epoch_val_samples\n",
        "\n",
        "        # Compute final metrics after all epochs\n",
        "        avg_train_loss = total_train_loss / total_train_samples\n",
        "        avg_train_accuracy = total_train_correct / total_train_samples * 100\n",
        "        avg_val_loss = total_val_loss / total_val_samples\n",
        "        avg_val_accuracy = total_val_correct / total_val_samples * 100\n",
        "\n",
        "        print(f\"Fold {fold+1} results: \")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.2f}%\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.2f}%\")\n",
        "\n",
        "        results.append((avg_train_loss, avg_train_accuracy, avg_val_loss, avg_val_accuracy))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run K-Fold cross-validation\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'  # Replace with your actual data directory\n",
        "\n",
        "# Assuming you have the center of the midbrain defined, for example:\n",
        "midbrain_center = (64,64,64)  # Replace with your actual midbrain center coordinates\n",
        "\n",
        "# Create the dataset instance\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "# Set k for K-Fold cross-validation\n",
        "k = 5\n",
        "\n",
        "# Run K-Fold cross-validation with the custom model\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueCUeLLVoo6H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(30, 30, 30), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model, dropout_rate=0.5):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "        self.dropout = nn.Dropout3d(p=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model(x)\n",
        "      x = self.dropout(x)\n",
        "      return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20, patience=5):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=patience)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoader for training and validation\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = model_class(original_model)\n",
        "        model.to(device)\n",
        "\n",
        "        # Initialize optimizer, loss function, and scheduler\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)  # Learning rate scheduler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialize accumulators for metrics\n",
        "        total_train_loss, total_train_correct = 0.0, 0\n",
        "        total_train_samples = 0\n",
        "        total_val_loss, total_val_correct = 0.0, 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # Initialize lists to accumulate true labels and predictions for metrics\n",
        "        all_train_labels = []\n",
        "        all_train_preds = []\n",
        "        all_val_labels = []\n",
        "        all_val_preds = []\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            epoch_train_loss, epoch_train_correct = 0.0, 0\n",
        "            epoch_train_samples = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                epoch_train_correct += (predicted == labels).sum().item()\n",
        "                epoch_train_samples += labels.size(0)\n",
        "\n",
        "                all_train_labels.extend(labels.cpu().numpy())\n",
        "                all_train_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            total_train_loss += epoch_train_loss\n",
        "            total_train_correct += epoch_train_correct\n",
        "            total_train_samples += epoch_train_samples\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            epoch_val_loss, epoch_val_correct = 0.0, 0\n",
        "            epoch_val_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    epoch_val_correct += (predicted == labels).sum().item()\n",
        "                    epoch_val_samples += labels.size(0)\n",
        "\n",
        "                    all_val_labels.extend(labels.cpu().numpy())\n",
        "                    all_val_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            total_val_loss += epoch_val_loss\n",
        "            total_val_correct += epoch_val_correct\n",
        "            total_val_samples += epoch_val_samples\n",
        "\n",
        "            # Early stopping check\n",
        "            early_stopping(total_val_loss / total_val_samples)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "            # Learning rate scheduler step\n",
        "            scheduler.step(total_val_loss / total_val_samples)\n",
        "\n",
        "        # Compute final metrics after all epochs\n",
        "        avg_train_loss = total_train_loss / total_train_samples\n",
        "        avg_train_accuracy = total_train_correct / total_train_samples * 100\n",
        "        avg_val_loss = total_val_loss / total_val_samples\n",
        "        avg_val_accuracy = total_val_correct / total_val_samples * 100\n",
        "\n",
        "        # Calculate additional metrics (precision, recall, F1, etc.)\n",
        "        train_precision = precision_score(all_train_labels, all_train_preds, average='macro')\n",
        "        train_recall = recall_score(all_train_labels, all_train_preds, average='macro')\n",
        "        train_f1 = f1_score(all_train_labels, all_train_preds, average='macro')\n",
        "        val_precision = precision_score(all_val_labels, all_val_preds, average='macro')\n",
        "        val_recall = recall_score(all_val_labels, all_val_preds, average='macro')\n",
        "        val_f1 = f1_score(all_val_labels, all_val_preds, average='macro')\n",
        "\n",
        "        print(f\"Fold {fold+1} results: \")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.2f}%\")\n",
        "        print(f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.2f}%\")\n",
        "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Store the metrics for later analysis\n",
        "        results.append({\n",
        "            'train_loss': avg_train_loss,\n",
        "            'train_accuracy': avg_train_accuracy,\n",
        "            'train_precision': train_precision,\n",
        "            'train_recall': train_recall,\n",
        "            'train_f1': train_f1,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'val_accuracy': avg_val_accuracy,\n",
        "            'val_precision': val_precision,\n",
        "            'val_recall': val_recall,\n",
        "            'val_f1': val_f1\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run K-Fold cross-validation with early stopping, dropout, and learning rate scheduler\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'  # Replace with your actual data directory\n",
        "midbrain_center = (64, 64, 64)  # Replace with your actual midbrain center coordinates\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "k = 5\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=50, patience=5)\n",
        "\n",
        "# Print the final K-Fold results\n",
        "print(\"K-Fold Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQX5Re5xSwsr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(50, 50, 50), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoader for training and validation\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = model_class(original_model)\n",
        "        model.to(device)\n",
        "\n",
        "        # Initialize accumulators for metrics\n",
        "        total_train_loss, total_train_correct = 0.0, 0\n",
        "        total_train_samples = 0\n",
        "        total_val_loss, total_val_correct = 0.0, 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            epoch_train_loss, epoch_train_correct = 0.0, 0\n",
        "            epoch_train_samples = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                epoch_train_correct += (predicted == labels).sum().item()\n",
        "                epoch_train_samples += labels.size(0)\n",
        "\n",
        "            total_train_loss += epoch_train_loss\n",
        "            total_train_correct += epoch_train_correct\n",
        "            total_train_samples += epoch_train_samples\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            epoch_val_loss, epoch_val_correct = 0.0, 0\n",
        "            epoch_val_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    epoch_val_correct += (predicted == labels).sum().item()\n",
        "                    epoch_val_samples += labels.size(0)\n",
        "\n",
        "            total_val_loss += epoch_val_loss\n",
        "            total_val_correct += epoch_val_correct\n",
        "            total_val_samples += epoch_val_samples\n",
        "\n",
        "        # Compute final metrics after all epochs\n",
        "        avg_train_loss = total_train_loss / total_train_samples\n",
        "        avg_train_accuracy = total_train_correct / total_train_samples * 100\n",
        "        avg_val_loss = total_val_loss / total_val_samples\n",
        "        avg_val_accuracy = total_val_correct / total_val_samples * 100\n",
        "\n",
        "        print(f\"Fold {fold+1} results: \")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.2f}%\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.2f}%\")\n",
        "\n",
        "        results.append((avg_train_loss, avg_train_accuracy, avg_val_loss, avg_val_accuracy))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run K-Fold cross-validation\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'  # Replace with your actual data directory\n",
        "\n",
        "# Assuming you have the center of the midbrain defined, for example:\n",
        "midbrain_center = (64,64,64)  # Replace with your actual midbrain center coordinates\n",
        "\n",
        "# Create the dataset instance\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "# Set k for K-Fold cross-validation\n",
        "k = 5\n",
        "\n",
        "# Run K-Fold cross-validation with the custom model\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgKUiOum1XDK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(50, 50, 50), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "        # Add Dropout after the stem\n",
        "        self.dropout = nn.Dropout3d(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.stem(x)\n",
        "        x = self.dropout(x)   # Apply dropout early\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.model.fc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20, patience=5):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        model = model_class(models.video.r3d_18(pretrained=True))\n",
        "        model.to(device)\n",
        "\n",
        "        # Apply weight decay (L2 regularization)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            epoch_train_loss, epoch_train_correct = 0.0, 0\n",
        "            epoch_train_samples = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                epoch_train_correct += (predicted == labels).sum().item()\n",
        "                epoch_train_samples += labels.size(0)\n",
        "\n",
        "            model.eval()\n",
        "            epoch_val_loss, epoch_val_correct = 0.0, 0\n",
        "            epoch_val_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    epoch_val_correct += (predicted == labels).sum().item()\n",
        "                    epoch_val_samples += labels.size(0)\n",
        "\n",
        "            avg_train_loss = epoch_train_loss / epoch_train_samples\n",
        "            avg_train_accuracy = epoch_train_correct / epoch_train_samples * 100\n",
        "            avg_val_loss = epoch_val_loss / epoch_val_samples\n",
        "            avg_val_accuracy = epoch_val_correct / epoch_val_samples * 100\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_accuracy:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_accuracy:.2f}%\")\n",
        "\n",
        "            # Early Stopping Check\n",
        "            if avg_val_loss < best_val_loss:\n",
        "                best_val_loss = avg_val_loss\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        results.append((avg_train_loss, avg_train_accuracy, avg_val_loss, avg_val_accuracy))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "midbrain_center = (64, 64, 64)\n",
        "\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "k = 5\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=35, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pazInl3tj95i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "\n",
        "        # Shuffle the samples (to prevent any loading bias)\n",
        "        self.samples = [(f, 0) for f in hc_files] + [(f, 1) for f in pd_files]\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "        self.dropout = nn.Dropout3d(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.stem(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.model.fc(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20, patience=5):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"\\n--- Training Fold {fold+1}/{k} ---\")\n",
        "\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        model = model_class(models.video.r3d_18(pretrained=True)).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        best_val_loss = np.inf\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            running_train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_train_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                train_correct += (preds == labels).sum().item()\n",
        "                train_total += labels.size(0)\n",
        "\n",
        "            train_loss = running_train_loss / train_total\n",
        "            train_acc = train_correct / train_total * 100\n",
        "\n",
        "            model.eval()\n",
        "            running_val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    running_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    val_correct += (preds == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "            val_loss = running_val_loss / val_total\n",
        "            val_acc = val_correct / val_total * 100\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model_wts = model.state_dict().copy()\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        model.load_state_dict(best_model_wts)\n",
        "        results.append((train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage:\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "midbrain_center = (64, 64, 64)\n",
        "\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "k = 5\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=35, patience=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsQK2x7GsfJc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "from torchvision import models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None):\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        for file in hc_files:\n",
        "            self.samples.append((file, 0))  # Label 0 for Healthy controls\n",
        "\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "        for file in pd_files:\n",
        "            self.samples.append((file, 1))  # Label 1 for Parkinson's patients\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center, size=(30, 30, 30)):\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "        x_start, y_start, z_start = max(x_center - d//2, 0), max(y_center - h//2, 0), max(z_center - w//2, 0)\n",
        "        x_end, y_end, z_end = min(x_center + d//2, volume.shape[0]), min(y_center + h//2, volume.shape[1]), min(z_center + w//2, volume.shape[2])\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "        volume = np.load(file_path)  # Load the 3D MRI volume\n",
        "\n",
        "        if volume.ndim == 4:\n",
        "            volume = volume.squeeze(0)  # Drop the channel dimension if present\n",
        "\n",
        "        midbrain_region = self.extract_midbrain_region(volume, self.midbrain_center, self.region_size)\n",
        "\n",
        "        if midbrain_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array, but got {midbrain_region.ndim}D\")\n",
        "\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, np.array((64, 64, 64)) / np.array(midbrain_region.shape), order=1)\n",
        "\n",
        "        if resized_region.ndim != 3:\n",
        "            raise ValueError(f\"Expected a 3D array after resizing, but got {resized_region.ndim}D\")\n",
        "\n",
        "        resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region) + 1e-8)\n",
        "\n",
        "        resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            resized_region = self.transform(resized_region)\n",
        "\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        return resized_region, label\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, original_model, dropout_rate=0.5):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "        original_model.stem[0] = nn.Conv3d(1, original_model.stem[0].out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.model = original_model\n",
        "        self.dropout = nn.Dropout3d(p=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model(x)\n",
        "      x = self.dropout(x)\n",
        "      return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained model\n",
        "original_model = models.video.r3d_18(pretrained=True)\n",
        "model = CustomResNet3D(original_model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, delta=0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "\n",
        "def k_fold_train_and_validate(model_class, dataset, k=5, num_epochs=20, patience=5):\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    results = []\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=patience)\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"Training fold {fold+1}/{k}...\")\n",
        "\n",
        "        # Create train and validation subsets\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        # DataLoader for training and validation\n",
        "        train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = model_class(original_model)\n",
        "        model.to(device)\n",
        "\n",
        "        # Initialize optimizer, loss function, and scheduler\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)  # Learning rate scheduler\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Initialize accumulators for metrics\n",
        "        total_train_loss, total_train_correct = 0.0, 0\n",
        "        total_train_samples = 0\n",
        "        total_val_loss, total_val_correct = 0.0, 0\n",
        "        total_val_samples = 0\n",
        "\n",
        "        # Initialize lists to accumulate true labels and predictions for metrics\n",
        "        all_train_labels = []\n",
        "        all_train_preds = []\n",
        "        all_val_labels = []\n",
        "        all_val_preds = []\n",
        "\n",
        "        # Training and validation loop\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            epoch_train_loss, epoch_train_correct = 0.0, 0\n",
        "            epoch_train_samples = 0\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                epoch_train_correct += (predicted == labels).sum().item()\n",
        "                epoch_train_samples += labels.size(0)\n",
        "\n",
        "                all_train_labels.extend(labels.cpu().numpy())\n",
        "                all_train_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            total_train_loss += epoch_train_loss\n",
        "            total_train_correct += epoch_train_correct\n",
        "            total_train_samples += epoch_train_samples\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            epoch_val_loss, epoch_val_correct = 0.0, 0\n",
        "            epoch_val_samples = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    epoch_val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    epoch_val_correct += (predicted == labels).sum().item()\n",
        "                    epoch_val_samples += labels.size(0)\n",
        "\n",
        "                    all_val_labels.extend(labels.cpu().numpy())\n",
        "                    all_val_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "            total_val_loss += epoch_val_loss\n",
        "            total_val_correct += epoch_val_correct\n",
        "            total_val_samples += epoch_val_samples\n",
        "\n",
        "            # Early stopping check\n",
        "            early_stopping(total_val_loss / total_val_samples)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "            # Learning rate scheduler step\n",
        "            scheduler.step(total_val_loss / total_val_samples)\n",
        "\n",
        "        # Compute final metrics after all epochs\n",
        "        avg_train_loss = total_train_loss / total_train_samples\n",
        "        avg_train_accuracy = total_train_correct / total_train_samples * 100\n",
        "        avg_val_loss = total_val_loss / total_val_samples\n",
        "        avg_val_accuracy = total_val_correct / total_val_samples * 100\n",
        "\n",
        "        # Calculate additional metrics (precision, recall, F1, etc.)\n",
        "        train_precision = precision_score(all_train_labels, all_train_preds, average='binary')\n",
        "        train_recall = recall_score(all_train_labels, all_train_preds, average='binary')\n",
        "        train_f1 = f1_score(all_train_labels, all_train_preds, average='binary')\n",
        "        val_precision = precision_score(all_val_labels, all_val_preds, average='binary')\n",
        "        val_recall = recall_score(all_val_labels, all_val_preds, average='binary')\n",
        "        val_f1 = f1_score(all_val_labels, all_val_preds, average='binary')\n",
        "\n",
        "        print(f\"Fold {fold+1} results: \")\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.2f}%\")\n",
        "        print(f\"Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}, Train F1: {train_f1:.4f}\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.2f}%\")\n",
        "        print(f\"Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Store the metrics for later analysis\n",
        "        results.append({\n",
        "            'train_loss': avg_train_loss,\n",
        "            'train_accuracy': avg_train_accuracy,\n",
        "            'train_precision': train_precision,\n",
        "            'train_recall': train_recall,\n",
        "            'train_f1': train_f1,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'val_accuracy': avg_val_accuracy,\n",
        "            'val_precision': val_precision,\n",
        "            'val_recall': val_recall,\n",
        "            'val_f1': val_f1\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run K-Fold cross-validation with early stopping, dropout, and learning rate scheduler\n",
        "data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'  # Replace with your actual data directory\n",
        "midbrain_center = (64, 64, 64)  # Replace with your actual midbrain center coordinates\n",
        "dataset = BrainRegionDataset(root_dir=data_dir, midbrain_center=midbrain_center)\n",
        "\n",
        "k = 5\n",
        "results = k_fold_train_and_validate(CustomResNet3D, dataset, k=k, num_epochs=25, patience=5)\n",
        "\n",
        "# Print the final K-Fold results\n",
        "print(\"K-Fold Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IAXn_EgylGw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace with your fold results:\n",
        "fold_accuracies = [88.89, 100, 77.78, 77.78, 75.00]\n",
        "fold_losses = [1.0395, 0.1230, 1.6371, 1.3380, 0.8132]\n",
        "\n",
        "mean_accuracy = np.mean(fold_accuracies)\n",
        "std_accuracy = np.std(fold_accuracies)\n",
        "\n",
        "mean_loss = np.mean(fold_losses)\n",
        "std_loss = np.std(fold_losses)\n",
        "\n",
        "print(f\"Mean Validation Accuracy: {mean_accuracy:.4f}\")\n",
        "print(f\"Std Dev of Validation Accuracy: {std_accuracy:.4f}\")\n",
        "print(f\"Mean Validation Loss: {mean_loss:.4f}\")\n",
        "print(f\"Std Dev of Validation Loss: {std_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O43x1BIyrTZM"
      },
      "source": [
        "#finding the mid brain region and estimating coordinated for substantia nigra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8QmtKgyrSrl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npy file\n",
        "volume = np.load(\"/content/drive/MyDrive/mri_hc/hc_subject1.npy\")  # should be shape like (H, W, D)\n",
        "print(volume.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIivCUbJsQzO"
      },
      "source": [
        "standard mni coordinates=(10,15,10) hence they can be assumed as (x,y,z)=(101,94,81) based on mni dimensions of (182,218,182)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULeMpPgesqmV"
      },
      "outputs": [],
      "source": [
        "def scale_coords(mni_coord, mni_shape, target_shape):\n",
        "    return tuple(\n",
        "        int(mni_coord[i] * target_shape[i] / mni_shape[i])\n",
        "        for i in range(3)\n",
        "    )\n",
        "\n",
        "mni_shape = (182, 218, 182)          # standard MNI shape (X, Y, Z)\n",
        "target_shape = (256, 256, 170)[::-1]  # (Z, Y, X) → flip to (X, Y, Z)\n",
        "\n",
        "mni_coord = (101, 94, 81)  # approximate SN center in MNI space\n",
        "scaled_center = scale_coords(mni_coord, mni_shape, target_shape)\n",
        "print(\"Approx SN center in your volume:\", scaled_center[::-1])  # convert back to (Z, Y, X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reMjnH64s3TG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "volume = np.load(\"/content/drive/MyDrive/mri_hc/hc_subject1.npy\")\n",
        "z, y, x = scaled_center[::-1]  # since your volume is (Z, Y, X)\n",
        "half = 32\n",
        "\n",
        "patch = volume[\n",
        "    z - half:z + half,\n",
        "    y - half:y + half,\n",
        "    x - half:x + half\n",
        "]\n",
        "\n",
        "print(\"Patch shape:\", patch.shape)  # should be (64, 64, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RmiEkMFtHRv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the patch if not already loaded\n",
        "# patch = np.load(\"your_64x64x64_patch.npy\")  # or use the patch variable from before\n",
        "\n",
        "# Get center indices\n",
        "center = patch.shape[0] // 2  # 32 for 64x64x64\n",
        "\n",
        "# Plot central slices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Axial (Z)\n",
        "axes[0].imshow(patch[center, :, :], cmap='gray')\n",
        "axes[0].set_title(\"Axial Slice (Z)\")\n",
        "\n",
        "# Coronal (Y)\n",
        "axes[1].imshow(patch[:, center, :], cmap='gray')\n",
        "axes[1].set_title(\"Coronal Slice (Y)\")\n",
        "\n",
        "# Sagittal (X)\n",
        "axes[2].imshow(patch[:, :, center], cmap='gray')\n",
        "axes[2].set_title(\"Sagittal Slice (X)\")\n",
        "\n",
        "for ax in axes:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETp3hO7MtoPZ"
      },
      "outputs": [],
      "source": [
        "z, y, x = 85,130,110  # Midbrain region\n",
        "half = 32\n",
        "\n",
        "patch = volume[\n",
        "    z - half:z + half,\n",
        "    y - half:y + half,\n",
        "    x - half:x + half\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfyhqLIxtrDu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the patch if not already loaded\n",
        "# patch = np.load(\"your_64x64x64_patch.npy\")  # or use the patch variable from before\n",
        "\n",
        "# Get center indices\n",
        "center = patch.shape[0] // 2  # 32 for 64x64x64\n",
        "\n",
        "# Plot central slices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Axial (Z)\n",
        "axes[0].imshow(patch[center, :, :], cmap='gray')\n",
        "axes[0].set_title(\"Axial Slice (Z)\")\n",
        "\n",
        "# Coronal (Y)\n",
        "axes[1].imshow(patch[:, center, :], cmap='gray')\n",
        "axes[1].set_title(\"Coronal Slice (Y)\")\n",
        "\n",
        "# Sagittal (X)\n",
        "axes[2].imshow(patch[:, :, center], cmap='gray')\n",
        "axes[2].set_title(\"Sagittal Slice (X)\")\n",
        "\n",
        "for ax in axes:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmxyUNaEysVl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the .npy file\n",
        "volume = np.load(\"/content/drive/MyDrive/mri_pd/pd_subject1.npy\")  # should be shape like (H, W, D)\n",
        "volume=volume[0]\n",
        "print(volume.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8k33UuIzCUs"
      },
      "outputs": [],
      "source": [
        "z,y,x=85,130,110\n",
        "half=32\n",
        "patch = volume[\n",
        "    z - half:z + half,\n",
        "    y - half:y + half,\n",
        "    x - half:x + half\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "folnKfWz0DxI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the patch if not already loaded\n",
        "# patch = np.load(\"your_64x64x64_patch.npy\")  # or use the patch variable from before\n",
        "\n",
        "# Get center indices\n",
        "center = patch.shape[0] // 2  # 32 for 64x64x64\n",
        "\n",
        "# Plot central slices\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "# Axial (Z)\n",
        "axes[0].imshow(patch[center, :, :], cmap='gray')\n",
        "axes[0].set_title(\"Axial Slice (Z)\")\n",
        "\n",
        "# Coronal (Y)\n",
        "axes[1].imshow(patch[:, center, :], cmap='gray')\n",
        "axes[1].set_title(\"Coronal Slice (Y)\")\n",
        "\n",
        "# Sagittal (X)\n",
        "axes[2].imshow(patch[:, :, center], cmap='gray')\n",
        "axes[2].set_title(\"Sagittal Slice (X)\")\n",
        "\n",
        "for ax in axes:\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPqqtmVM1ydQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None):\n",
        "        \"\"\"\n",
        "        Dataset for brain region extraction focused on the substantia nigra.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing 'hc' and 'pd' subdirectories\n",
        "            midbrain_center: Coordinates of the midbrain center (x, y, z)\n",
        "            region_size: Size of the region to extract\n",
        "            transform: Optional transforms to apply\n",
        "        \"\"\"\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(hc_folder) or not os.path.exists(pd_folder):\n",
        "            raise FileNotFoundError(f\"HC or PD folder not found in {root_dir}\")\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "\n",
        "        print(f\"Found {len(hc_files)} healthy control samples and {len(pd_files)} Parkinson's disease samples\")\n",
        "\n",
        "        # Shuffle the samples\n",
        "        self.samples = [(f, 0) for f in hc_files] + [(f, 1) for f in pd_files]\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center=None, size=None):\n",
        "        \"\"\"\n",
        "        Extract region around substantia nigra from a brain volume.\n",
        "\n",
        "        Args:\n",
        "            volume: 3D numpy array of brain MRI\n",
        "            center: Center coordinates (x, y, z), defaults to self.midbrain_center\n",
        "            size: Size of region to extract (d, h, w), defaults to self.region_size\n",
        "\n",
        "        Returns:\n",
        "            3D numpy array of extracted region\n",
        "        \"\"\"\n",
        "        if center is None:\n",
        "            center = self.midbrain_center\n",
        "        if size is None:\n",
        "            size = self.region_size\n",
        "\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "\n",
        "        # Ensure center coordinates are within volume boundaries\n",
        "        x_center = min(max(x_center, d//2), volume.shape[0] - d//2)\n",
        "        y_center = min(max(y_center, h//2), volume.shape[1] - h//2)\n",
        "        z_center = min(max(z_center, w//2), volume.shape[2] - w//2)\n",
        "\n",
        "        x_start, y_start, z_start = x_center - d//2, y_center - h//2, z_center - w//2\n",
        "        x_end, y_end, z_end = x_start + d, y_start + h, z_start + w\n",
        "\n",
        "        # Double-check boundaries\n",
        "        x_start, y_start, z_start = max(x_start, 0), max(y_start, 0), max(z_start, 0)\n",
        "        x_end = min(x_end, volume.shape[0])\n",
        "        y_end = min(y_end, volume.shape[1])\n",
        "        z_end = min(z_end, volume.shape[2])\n",
        "\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            volume = np.load(file_path)\n",
        "\n",
        "            # Handle different volume formats\n",
        "            if volume.ndim == 4 and volume.shape[0] == 1:\n",
        "                volume = volume.squeeze(0)  # Remove batch dimension if present\n",
        "            elif volume.ndim > 3:\n",
        "                raise ValueError(f\"Unexpected volume shape: {volume.shape}\")\n",
        "\n",
        "            # Extract region around substantia nigra\n",
        "            midbrain_region = self.extract_midbrain_region(volume)\n",
        "\n",
        "            # Check if region was extracted properly\n",
        "            if 0 in midbrain_region.shape:\n",
        "                raise ValueError(f\"Extracted region has invalid shape: {midbrain_region.shape}\")\n",
        "\n",
        "            # Resize to consistent dimensions\n",
        "            target_shape = (64, 64, 64)\n",
        "            scale_factors = np.array(target_shape) / np.array(midbrain_region.shape)\n",
        "            resized_region = scipy.ndimage.zoom(midbrain_region, scale_factors, order=1)\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            if np.max(resized_region) > np.min(resized_region):\n",
        "                resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region))\n",
        "\n",
        "            # Convert to tensor with channel dimension\n",
        "            resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            if self.transform:\n",
        "                resized_region = self.transform(resized_region)\n",
        "\n",
        "            return resized_region, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {str(e)}\")\n",
        "            # Return a placeholder and keep track of errors\n",
        "            # In a production system, you'd want better error handling\n",
        "            placeholder = torch.zeros((1, 64, 64, 64), dtype=torch.float32)\n",
        "            return placeholder, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=2):\n",
        "        \"\"\"\n",
        "        3D ResNet model adapted for brain MRI classification.\n",
        "\n",
        "        Args:\n",
        "            pretrained: Whether to use pretrained weights\n",
        "            num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Start with pretrained R3D_18 model\n",
        "        base_model = models.video.r3d_18(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        base_model.stem[0] = nn.Conv3d(\n",
        "            1,\n",
        "            base_model.stem[0].out_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Modify final FC layer for binary classification\n",
        "        num_ftrs = base_model.fc.in_features\n",
        "        base_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "        self.model = base_model\n",
        "\n",
        "        # Add regularization\n",
        "        self.dropout = nn.Dropout3d(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.stem(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.model.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Run one training epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Save predictions and labels for metrics\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return running_loss / total, correct / total, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "def k_fold_train_and_validate(dataset, k=5, num_epochs=20, batch_size=4,\n",
        "                             learning_rate=1e-4, weight_decay=1e-4, patience=5):\n",
        "    \"\"\"\n",
        "    Train and validate using k-fold cross validation.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        k: Number of folds\n",
        "        num_epochs: Maximum number of training epochs\n",
        "        batch_size: Batch size for training\n",
        "        learning_rate: Initial learning rate\n",
        "        weight_decay: L2 regularization strength\n",
        "        patience: Early stopping patience\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of results for each fold\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Extract labels for stratified splitting\n",
        "    labels = [label for _, label in dataset.samples]\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'train_losses': [],\n",
        "        'train_accs': [],\n",
        "        'val_losses': [],\n",
        "        'val_accs': [],\n",
        "        'best_models': []\n",
        "    }\n",
        "\n",
        "    # Class weights for imbalanced data\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = torch.tensor(len(labels) / (len(class_counts) * class_counts), dtype=torch.float32)\n",
        "\n",
        "    # Train and validate for each fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
        "        print(f\"\\n{'='*40}\\nTraining Fold {fold+1}/{k}\\n{'='*40}\")\n",
        "\n",
        "        # Create data subsets and loaders\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
        "                                 num_workers=4, pin_memory=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=4, pin_memory=True)\n",
        "\n",
        "        # Initialize model, optimizer, and criterion\n",
        "        model = CustomResNet3D(pretrained=True).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
        "        )\n",
        "\n",
        "        # Use weighted loss for imbalanced data\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "        # Track best model and metrics\n",
        "        best_val_loss = float('inf')\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        # Training history\n",
        "        fold_train_losses = []\n",
        "        fold_train_accs = []\n",
        "        fold_val_losses = []\n",
        "        fold_val_accs = []\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            # Train\n",
        "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "            fold_train_losses.append(train_loss)\n",
        "            fold_train_accs.append(train_acc)\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
        "            fold_val_losses.append(val_loss)\n",
        "            fold_val_accs.append(val_acc)\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if val_loss < best_val_loss:\n",
        "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}\")\n",
        "                best_val_loss = val_loss\n",
        "                best_model_wts = model.state_dict().copy()\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                print(f\"Validation loss did not improve. Early stopping counter: {early_stop_counter}/{patience}\")\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        # Load best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Final validation with best model\n",
        "        final_val_loss, final_val_acc, final_preds, final_labels = validate(model, val_loader, criterion, device)\n",
        "        print(f\"\\nFinal validation - Loss: {final_val_loss:.4f}, Acc: {final_val_acc*100:.2f}%\")\n",
        "\n",
        "        # Save fold results\n",
        "        results['train_losses'].append(fold_train_losses)\n",
        "        results['train_accs'].append(fold_train_accs)\n",
        "        results['val_losses'].append(fold_val_losses)\n",
        "        results['val_accs'].append(fold_val_accs)\n",
        "        results['best_models'].append(model.state_dict().copy())\n",
        "\n",
        "        # Save model for this fold\n",
        "        torch.save({\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_acc': final_val_acc,\n",
        "            'val_loss': final_val_loss\n",
        "        }, f'best_model_fold_{fold}.pth')\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_val_acc = np.mean([results['val_accs'][i][-1] for i in range(k)])\n",
        "    print(f\"\\nAverage validation accuracy across {k} folds: {avg_val_acc*100:.2f}%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def visualize_region(dataset, idx=0, slice_dim=0, slice_pos=32):\n",
        "    \"\"\"\n",
        "    Visualize a brain region from the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        idx: Index of sample to visualize\n",
        "        slice_dim: Dimension to slice (0=sagittal, 1=coronal, 2=axial)\n",
        "        slice_pos: Position of slice\n",
        "    \"\"\"\n",
        "    volume, label = dataset[idx]\n",
        "    volume = volume.squeeze(0).numpy()  # Remove channel dimension\n",
        "\n",
        "    class_name = \"Parkinson's Disease\" if label.item() == 1 else \"Healthy Control\"\n",
        "\n",
        "    # Get a slice\n",
        "    if slice_dim == 0:\n",
        "        slice_name = \"Sagittal\"\n",
        "        img_slice = volume[slice_pos, :, :]\n",
        "    elif slice_dim == 1:\n",
        "        slice_name = \"Coronal\"\n",
        "        img_slice = volume[:, slice_pos, :]\n",
        "    else:\n",
        "        slice_name = \"Axial\"\n",
        "        img_slice = volume[:, :, slice_pos]\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img_slice, cmap='gray')\n",
        "    plt.title(f\"{slice_name} Slice - {class_name}\")\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Set data directory and substantia nigra center coordinates\n",
        "    data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "\n",
        "    # These should be the coordinates of the substantia nigra in your dataset\n",
        "    # You might need to adjust these based on your specific dataset\n",
        "    substantia_nigra_center = (96, 128, 128)  # Example coordinates (x, y, z)\n",
        "    region_size = (64, 64, 64)  # Size of region to extract\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = BrainRegionDataset(\n",
        "        root_dir=data_dir,\n",
        "        midbrain_center=substantia_nigra_center,\n",
        "        region_size=region_size\n",
        "    )\n",
        "\n",
        "    # Visualize a few samples to verify\n",
        "    for i in range(min(3, len(dataset))):\n",
        "        print(f\"\\nVisualizing sample {i}\")\n",
        "        # View axial slice\n",
        "        visualize_region(dataset, idx=i, slice_dim=2, slice_pos=32)\n",
        "\n",
        "    # Set training parameters\n",
        "    params = {\n",
        "        'k': 5,\n",
        "        'num_epochs': 35,\n",
        "        'batch_size': 4,\n",
        "        'learning_rate': 1e-4,\n",
        "        'weight_decay': 1e-4,\n",
        "        'patience': 5\n",
        "    }\n",
        "\n",
        "    # Run k-fold cross-validation\n",
        "    results = k_fold_train_and_validate(dataset, **params)\n",
        "\n",
        "    # Plot learning curves\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(results['train_losses'][fold], label=f'Fold {fold+1} Train')\n",
        "        plt.plot(results['val_losses'][fold], label=f'Fold {fold+1} Val')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(np.array(results['train_accs'][fold])*100, label=f'Fold {fold+1} Train')\n",
        "        plt.plot(np.array(results['val_accs'][fold])*100, label=f'Fold {fold+1} Val')\n",
        "    plt.title('Accuracy vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wceT96th_OS-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None):\n",
        "        \"\"\"\n",
        "        Dataset for brain region extraction focused on the substantia nigra.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing 'hc' and 'pd' subdirectories\n",
        "            midbrain_center: Coordinates of the midbrain center (x, y, z)\n",
        "            region_size: Size of the region to extract\n",
        "            transform: Optional transforms to apply\n",
        "        \"\"\"\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(hc_folder) or not os.path.exists(pd_folder):\n",
        "            raise FileNotFoundError(f\"HC or PD folder not found in {root_dir}\")\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "\n",
        "        print(f\"Found {len(hc_files)} healthy control samples and {len(pd_files)} Parkinson's disease samples\")\n",
        "\n",
        "        # Shuffle the samples\n",
        "        self.samples = [(f, 0) for f in hc_files] + [(f, 1) for f in pd_files]\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center=None, size=None):\n",
        "        \"\"\"\n",
        "        Extract region around substantia nigra from a brain volume.\n",
        "\n",
        "        Args:\n",
        "            volume: 3D numpy array of brain MRI\n",
        "            center: Center coordinates (x, y, z), defaults to self.midbrain_center\n",
        "            size: Size of region to extract (d, h, w), defaults to self.region_size\n",
        "\n",
        "        Returns:\n",
        "            3D numpy array of extracted region\n",
        "        \"\"\"\n",
        "        if center is None:\n",
        "            center = self.midbrain_center\n",
        "        if size is None:\n",
        "            size = self.region_size\n",
        "\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "\n",
        "        # Ensure center coordinates are within volume boundaries\n",
        "        x_center = min(max(x_center, d//2), volume.shape[0] - d//2)\n",
        "        y_center = min(max(y_center, h//2), volume.shape[1] - h//2)\n",
        "        z_center = min(max(z_center, w//2), volume.shape[2] - w//2)\n",
        "\n",
        "        x_start, y_start, z_start = x_center - d//2, y_center - h//2, z_center - w//2\n",
        "        x_end, y_end, z_end = x_start + d, y_start + h, z_start + w\n",
        "\n",
        "        # Double-check boundaries\n",
        "        x_start, y_start, z_start = max(x_start, 0), max(y_start, 0), max(z_start, 0)\n",
        "        x_end = min(x_end, volume.shape[0])\n",
        "        y_end = min(y_end, volume.shape[1])\n",
        "        z_end = min(z_end, volume.shape[2])\n",
        "\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            volume = np.load(file_path)\n",
        "\n",
        "            # Handle different volume formats\n",
        "            if volume.ndim == 4 and volume.shape[0] == 1:\n",
        "                volume = volume.squeeze(0)  # Remove batch dimension if present\n",
        "            elif volume.ndim > 3:\n",
        "                raise ValueError(f\"Unexpected volume shape: {volume.shape}\")\n",
        "\n",
        "            # Extract region around substantia nigra\n",
        "            midbrain_region = self.extract_midbrain_region(volume)\n",
        "\n",
        "            # Check if region was extracted properly\n",
        "            if 0 in midbrain_region.shape:\n",
        "                raise ValueError(f\"Extracted region has invalid shape: {midbrain_region.shape}\")\n",
        "\n",
        "            # Resize to consistent dimensions\n",
        "            target_shape = (64, 64, 64)\n",
        "            scale_factors = np.array(target_shape) / np.array(midbrain_region.shape)\n",
        "            resized_region = scipy.ndimage.zoom(midbrain_region, scale_factors, order=1)\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            if np.max(resized_region) > np.min(resized_region):\n",
        "                resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region))\n",
        "\n",
        "            # Convert to tensor with channel dimension\n",
        "            resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            if self.transform:\n",
        "                resized_region = self.transform(resized_region)\n",
        "\n",
        "            return resized_region, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {str(e)}\")\n",
        "            # Return a placeholder and keep track of errors\n",
        "            # In a production system, you'd want better error handling\n",
        "            placeholder = torch.zeros((1, 64, 64, 64), dtype=torch.float32)\n",
        "            return placeholder, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=2):\n",
        "        \"\"\"\n",
        "        3D ResNet model adapted for brain MRI classification.\n",
        "\n",
        "        Args:\n",
        "            pretrained: Whether to use pretrained weights\n",
        "            num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Start with pretrained R3D_18 model\n",
        "        base_model = models.video.r3d_18(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        base_model.stem[0] = nn.Conv3d(\n",
        "            1,\n",
        "            base_model.stem[0].out_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Modify final FC layer for binary classification\n",
        "        num_ftrs = base_model.fc.in_features\n",
        "        base_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "        self.model = base_model\n",
        "\n",
        "        # Add regularization\n",
        "        self.dropout = nn.Dropout3d(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.stem(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.model.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Run one training epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Save predictions and labels for metrics\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return running_loss / total, correct / total, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "def k_fold_train_and_validate(dataset, k=5, num_epochs=20, batch_size=4,\n",
        "                             learning_rate=1e-4, weight_decay=1e-4, patience=5):\n",
        "    \"\"\"\n",
        "    Train and validate using k-fold cross validation.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        k: Number of folds\n",
        "        num_epochs: Maximum number of training epochs\n",
        "        batch_size: Batch size for training\n",
        "        learning_rate: Initial learning rate\n",
        "        weight_decay: L2 regularization strength\n",
        "        patience: Early stopping patience\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of results for each fold\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Extract labels for stratified splitting\n",
        "    labels = [label for _, label in dataset.samples]\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'train_losses': [],\n",
        "        'train_accs': [],\n",
        "        'val_losses': [],\n",
        "        'val_accs': [],\n",
        "        'best_models': []\n",
        "    }\n",
        "\n",
        "    # Class weights for imbalanced data\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = torch.tensor(len(labels) / (len(class_counts) * class_counts), dtype=torch.float32)\n",
        "\n",
        "    # Train and validate for each fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
        "        print(f\"\\n{'='*40}\\nTraining Fold {fold+1}/{k}\\n{'='*40}\")\n",
        "\n",
        "        # Create data subsets and loaders\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
        "                                 num_workers=4, pin_memory=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=4, pin_memory=True)\n",
        "\n",
        "        # Initialize model, optimizer, and criterion\n",
        "        model = CustomResNet3D(pretrained=True).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
        "        )\n",
        "\n",
        "        # Use weighted loss for imbalanced data\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "        # Track best model and metrics\n",
        "        best_val_loss = float('inf')\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        # Training history\n",
        "        fold_train_losses = []\n",
        "        fold_train_accs = []\n",
        "        fold_val_losses = []\n",
        "        fold_val_accs = []\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            # Train\n",
        "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "            fold_train_losses.append(train_loss)\n",
        "            fold_train_accs.append(train_acc)\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
        "            fold_val_losses.append(val_loss)\n",
        "            fold_val_accs.append(val_acc)\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if val_loss < best_val_loss:\n",
        "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}\")\n",
        "                best_val_loss = val_loss\n",
        "                best_model_wts = model.state_dict().copy()\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                print(f\"Validation loss did not improve. Early stopping counter: {early_stop_counter}/{patience}\")\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        # Load best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Final validation with best model\n",
        "        final_val_loss, final_val_acc, final_preds, final_labels = validate(model, val_loader, criterion, device)\n",
        "        print(f\"\\nFinal validation - Loss: {final_val_loss:.4f}, Acc: {final_val_acc*100:.2f}%\")\n",
        "\n",
        "        # Save fold results\n",
        "        results['train_losses'].append(fold_train_losses)\n",
        "        results['train_accs'].append(fold_train_accs)\n",
        "        results['val_losses'].append(fold_val_losses)\n",
        "        results['val_accs'].append(fold_val_accs)\n",
        "        results['best_models'].append(model.state_dict().copy())\n",
        "\n",
        "        # Save model for this fold\n",
        "        torch.save({\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_acc': final_val_acc,\n",
        "            'val_loss': final_val_loss\n",
        "        }, f'best_model2_fold_{fold}.pth')\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_val_acc = np.mean([results['val_accs'][i][-1] for i in range(k)])\n",
        "    print(f\"\\nAverage validation accuracy across {k} folds: {avg_val_acc*100:.2f}%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def visualize_region(dataset, idx=0, slice_dim=0, slice_pos=32):\n",
        "    \"\"\"\n",
        "    Visualize a brain region from the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        idx: Index of sample to visualize\n",
        "        slice_dim: Dimension to slice (0=sagittal, 1=coronal, 2=axial)\n",
        "        slice_pos: Position of slice\n",
        "    \"\"\"\n",
        "    volume, label = dataset[idx]\n",
        "    volume = volume.squeeze(0).numpy()  # Remove channel dimension\n",
        "\n",
        "    class_name = \"Parkinson's Disease\" if label.item() == 1 else \"Healthy Control\"\n",
        "\n",
        "    # Get a slice\n",
        "    if slice_dim == 0:\n",
        "        slice_name = \"Sagittal\"\n",
        "        img_slice = volume[slice_pos, :, :]\n",
        "    elif slice_dim == 1:\n",
        "        slice_name = \"Coronal\"\n",
        "        img_slice = volume[:, slice_pos, :]\n",
        "    else:\n",
        "        slice_name = \"Axial\"\n",
        "        img_slice = volume[:, :, slice_pos]\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img_slice, cmap='gray')\n",
        "    plt.title(f\"{slice_name} Slice - {class_name}\")\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Set data directory and substantia nigra center coordinates\n",
        "    data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "\n",
        "    # These should be the coordinates of the substantia nigra in your dataset\n",
        "    # You might need to adjust these based on your specific dataset\n",
        "    substantia_nigra_center = (85, 130, 110)  # Example coordinates (x, y, z)\n",
        "    region_size = (64, 64, 64)  # Size of region to extract\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = BrainRegionDataset(\n",
        "        root_dir=data_dir,\n",
        "        midbrain_center=substantia_nigra_center,\n",
        "        region_size=region_size\n",
        "    )\n",
        "\n",
        "    # Visualize a few samples to verify\n",
        "    for i in range(min(3, len(dataset))):\n",
        "        print(f\"\\nVisualizing sample {i}\")\n",
        "        # View axial slice\n",
        "        visualize_region(dataset, idx=i, slice_dim=2, slice_pos=32)\n",
        "\n",
        "    # Set training parameters\n",
        "    params = {\n",
        "        'k': 5,\n",
        "        'num_epochs': 35,\n",
        "        'batch_size': 4,\n",
        "        'learning_rate': 1e-4,\n",
        "        'weight_decay': 1e-4,\n",
        "        'patience': 5\n",
        "    }\n",
        "\n",
        "    # Run k-fold cross-validation\n",
        "    results = k_fold_train_and_validate(dataset, **params)\n",
        "\n",
        "    # Plot learning curves\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(results['train_losses'][fold], label=f'Fold {fold+1} Train')\n",
        "        plt.plot(results['val_losses'][fold], label=f'Fold {fold+1} Val')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(np.array(results['train_accs'][fold])*100, label=f'Fold {fold+1} Train')\n",
        "        plt.plot(np.array(results['val_accs'][fold])*100, label=f'Fold {fold+1} Val')\n",
        "    plt.title('Accuracy vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJTWSAWJFcy5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None):\n",
        "        \"\"\"\n",
        "        Dataset for brain region extraction focused on the substantia nigra.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing 'hc' and 'pd' subdirectories\n",
        "            midbrain_center: Coordinates of the midbrain center (x, y, z)\n",
        "            region_size: Size of the region to extract\n",
        "            transform: Optional transforms to apply\n",
        "        \"\"\"\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(hc_folder) or not os.path.exists(pd_folder):\n",
        "            raise FileNotFoundError(f\"HC or PD folder not found in {root_dir}\")\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "\n",
        "        print(f\"Found {len(hc_files)} healthy control samples and {len(pd_files)} Parkinson's disease samples\")\n",
        "\n",
        "        # Shuffle the samples\n",
        "        self.samples = [(f, 0) for f in hc_files] + [(f, 1) for f in pd_files]\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center=None, size=None):\n",
        "        \"\"\"\n",
        "        Extract region around substantia nigra from a brain volume.\n",
        "\n",
        "        Args:\n",
        "            volume: 3D numpy array of brain MRI\n",
        "            center: Center coordinates (x, y, z), defaults to self.midbrain_center\n",
        "            size: Size of region to extract (d, h, w), defaults to self.region_size\n",
        "\n",
        "        Returns:\n",
        "            3D numpy array of extracted region\n",
        "        \"\"\"\n",
        "        if center is None:\n",
        "            center = self.midbrain_center\n",
        "        if size is None:\n",
        "            size = self.region_size\n",
        "\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "\n",
        "        # Ensure center coordinates are within volume boundaries\n",
        "        x_center = min(max(x_center, d//2), volume.shape[0] - d//2)\n",
        "        y_center = min(max(y_center, h//2), volume.shape[1] - h//2)\n",
        "        z_center = min(max(z_center, w//2), volume.shape[2] - w//2)\n",
        "\n",
        "        x_start, y_start, z_start = x_center - d//2, y_center - h//2, z_center - w//2\n",
        "        x_end, y_end, z_end = x_start + d, y_start + h, z_start + w\n",
        "\n",
        "        # Double-check boundaries\n",
        "        x_start, y_start, z_start = max(x_start, 0), max(y_start, 0), max(z_start, 0)\n",
        "        x_end = min(x_end, volume.shape[0])\n",
        "        y_end = min(y_end, volume.shape[1])\n",
        "        z_end = min(z_end, volume.shape[2])\n",
        "\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            volume = np.load(file_path)\n",
        "\n",
        "            # Handle different volume formats\n",
        "            if volume.ndim == 4 and volume.shape[0] == 1:\n",
        "                volume = volume.squeeze(0)  # Remove batch dimension if present\n",
        "            elif volume.ndim > 3:\n",
        "                raise ValueError(f\"Unexpected volume shape: {volume.shape}\")\n",
        "\n",
        "            # Extract region around substantia nigra\n",
        "            midbrain_region = self.extract_midbrain_region(volume)\n",
        "\n",
        "            # Check if region was extracted properly\n",
        "            if 0 in midbrain_region.shape:\n",
        "                raise ValueError(f\"Extracted region has invalid shape: {midbrain_region.shape}\")\n",
        "\n",
        "            # Resize to consistent dimensions\n",
        "            target_shape = (64, 64, 64)\n",
        "            scale_factors = np.array(target_shape) / np.array(midbrain_region.shape)\n",
        "            resized_region = scipy.ndimage.zoom(midbrain_region, scale_factors, order=1)\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            if np.max(resized_region) > np.min(resized_region):\n",
        "                resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region))\n",
        "\n",
        "            # Convert to tensor with channel dimension\n",
        "            resized_region = torch.tensor(resized_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            if self.transform:\n",
        "                resized_region = self.transform(resized_region)\n",
        "\n",
        "            return resized_region, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {str(e)}\")\n",
        "            # Return a placeholder and keep track of errors\n",
        "            # In a production system, you'd want better error handling\n",
        "            placeholder = torch.zeros((1, 64, 64, 64), dtype=torch.float32)\n",
        "            return placeholder, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=2):\n",
        "        \"\"\"\n",
        "        3D ResNet model adapted for brain MRI classification.\n",
        "\n",
        "        Args:\n",
        "            pretrained: Whether to use pretrained weights\n",
        "            num_classes: Number of output classes\n",
        "        \"\"\"\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Start with pretrained R3D_18 model\n",
        "        base_model = models.video.r3d_18(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        base_model.stem[0] = nn.Conv3d(\n",
        "            1,\n",
        "            base_model.stem[0].out_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Modify final FC layer for binary classification\n",
        "        num_ftrs = base_model.fc.in_features\n",
        "        base_model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "        self.model = base_model\n",
        "\n",
        "        # Add regularization\n",
        "        self.dropout = nn.Dropout3d(p=0.45)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model.stem(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.model.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Run one training epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Save predictions and labels for metrics\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return running_loss / total, correct / total, np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "\n",
        "def k_fold_train_and_validate(dataset, k=5, num_epochs=20, batch_size=8,\n",
        "                             learning_rate=5e-5, weight_decay=1e-4, patience=5):\n",
        "    \"\"\"\n",
        "    Train and validate using k-fold cross validation.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        k: Number of folds\n",
        "        num_epochs: Maximum number of training epochs\n",
        "        batch_size: Batch size for training\n",
        "        learning_rate: Initial learning rate\n",
        "        weight_decay: L2 regularization strength\n",
        "        patience: Early stopping patience\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of results for each fold\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Extract labels for stratified splitting\n",
        "    labels = [label for _, label in dataset.samples]\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'train_losses': [],\n",
        "        'train_accs': [],\n",
        "        'val_losses': [],\n",
        "        'val_accs': [],\n",
        "        'best_models': []\n",
        "    }\n",
        "\n",
        "    # Class weights for imbalanced data\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = torch.tensor(len(labels) / (len(class_counts) * class_counts), dtype=torch.float32)\n",
        "\n",
        "    # Train and validate for each fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
        "        print(f\"\\n{'='*40}\\nTraining Fold {fold+1}/{k}\\n{'='*40}\")\n",
        "\n",
        "        # Create data subsets and loaders\n",
        "        train_subset = Subset(dataset, train_idx)\n",
        "        val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True,\n",
        "                                 num_workers=4, pin_memory=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False,\n",
        "                               num_workers=4, pin_memory=True)\n",
        "\n",
        "        # Initialize model, optimizer, and criterion\n",
        "        model = CustomResNet3D(pretrained=True).to(device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
        "        )\n",
        "\n",
        "        # Use weighted loss for imbalanced data\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "        # Track best model and metrics\n",
        "        best_val_loss = float('inf')\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        # Training history\n",
        "        fold_train_losses = []\n",
        "        fold_train_accs = []\n",
        "        fold_val_losses = []\n",
        "        fold_val_accs = []\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            # Train\n",
        "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "            fold_train_losses.append(train_loss)\n",
        "            fold_train_accs.append(train_acc)\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
        "            fold_val_losses.append(val_loss)\n",
        "            fold_val_accs.append(val_acc)\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if val_loss < best_val_loss:\n",
        "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}\")\n",
        "                best_val_loss = val_loss\n",
        "                best_model_wts = model.state_dict().copy()\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                print(f\"Validation loss did not improve. Early stopping counter: {early_stop_counter}/{patience}\")\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        # Load best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Final validation with best model\n",
        "        final_val_loss, final_val_acc, final_preds, final_labels = validate(model, val_loader, criterion, device)\n",
        "        print(f\"\\nFinal validation - Loss: {final_val_loss:.4f}, Acc: {final_val_acc*100:.2f}%\")\n",
        "\n",
        "        # Save fold results\n",
        "        results['train_losses'].append(fold_train_losses)\n",
        "        results['train_accs'].append(fold_train_accs)\n",
        "        results['val_losses'].append(fold_val_losses)\n",
        "        results['val_accs'].append(fold_val_accs)\n",
        "        results['best_models'].append(model.state_dict().copy())\n",
        "\n",
        "        # Save model for this fold\n",
        "        torch.save({\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_acc': final_val_acc,\n",
        "            'val_loss': final_val_loss\n",
        "        }, f'best_model2_fold_{fold}.pth')\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_val_acc = np.mean([results['val_accs'][i][-1] for i in range(k)])\n",
        "    print(f\"\\nAverage validation accuracy across {k} folds: {avg_val_acc*100:.2f}%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def visualize_region(dataset, idx=0, slice_dim=0, slice_pos=32):\n",
        "    \"\"\"\n",
        "    Visualize a brain region from the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        idx: Index of sample to visualize\n",
        "        slice_dim: Dimension to slice (0=sagittal, 1=coronal, 2=axial)\n",
        "        slice_pos: Position of slice\n",
        "    \"\"\"\n",
        "    volume, label = dataset[idx]\n",
        "    volume = volume.squeeze(0).numpy()  # Remove channel dimension\n",
        "\n",
        "    class_name = \"Parkinson's Disease\" if label.item() == 1 else \"Healthy Control\"\n",
        "\n",
        "    # Get a slice\n",
        "    if slice_dim == 0:\n",
        "        slice_name = \"Sagittal\"\n",
        "        img_slice = volume[slice_pos, :, :]\n",
        "    elif slice_dim == 1:\n",
        "        slice_name = \"Coronal\"\n",
        "        img_slice = volume[:, slice_pos, :]\n",
        "    else:\n",
        "        slice_name = \"Axial\"\n",
        "        img_slice = volume[:, :, slice_pos]\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img_slice, cmap='gray')\n",
        "    plt.title(f\"{slice_name} Slice - {class_name}\")\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Set data directory and substantia nigra center coordinates\n",
        "    data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'\n",
        "\n",
        "    # These should be the coordinates of the substantia nigra in your dataset\n",
        "    # You might need to adjust these based on your specific dataset\n",
        "    substantia_nigra_center = (85, 130, 110)  # Example coordinates (x, y, z)\n",
        "    region_size = (64, 64, 64)  # Size of region to extract\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = BrainRegionDataset(\n",
        "        root_dir=data_dir,\n",
        "        midbrain_center=substantia_nigra_center,\n",
        "        region_size=region_size\n",
        "    )\n",
        "\n",
        "    # Visualize a few samples to verify\n",
        "    for i in range(min(3, len(dataset))):\n",
        "        print(f\"\\nVisualizing sample {i}\")\n",
        "        # View axial slice\n",
        "        visualize_region(dataset, idx=i, slice_dim=2, slice_pos=32)\n",
        "\n",
        "    # Set training parameters\n",
        "    params = {\n",
        "        'k': 5,\n",
        "        'num_epochs': 35,\n",
        "        'batch_size': 4,\n",
        "        'learning_rate': 1e-4,\n",
        "        'weight_decay': 1e-4,\n",
        "        'patience': 5\n",
        "    }\n",
        "\n",
        "    # Run k-fold cross-validation\n",
        "    results = k_fold_train_and_validate(dataset, **params)\n",
        "\n",
        "    # Plot learning curves\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(results['train_losses'][fold], label=f'Fold {fold+1} Train')\n",
        "        plt.plot(results['val_losses'][fold], label=f'Fold {fold+1} Val')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for fold in range(params['k']):\n",
        "        plt.plot(np.array(results['train_accs'][fold])*100, label=f'Fold {fold+1} Train')\n",
        "        plt.plot(np.array(results['val_accs'][fold])*100, label=f'Fold {fold+1} Val')\n",
        "    plt.title('Accuracy vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXGeCLltNXPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65570207-5692-48d8-c117-3d954ed541f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset...\n",
            "Found 49 healthy control samples and 49 Parkinson's disease samples\n",
            "Starting 5-fold cross-validation with auto_adapt model...\n",
            "Using device: cpu\n",
            "\n",
            "========================================\n",
            "Training Fold 1/5\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Training: 100%|██████████| 10/10 [06:17<00:00, 37.74s/it, loss=0.4919, acc=55.13%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] | Train Loss: 0.5098, Acc: 55.13% | Val Loss: 0.6947, Acc: 50.00% | LR: 0.000091 | Time: 377.4s\n",
            "Validation loss improved from inf to 0.6947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  30%|███       | 3/10 [01:59<04:24, 37.78s/it, loss=0.4882, acc=58.33%]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import copy\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class BrainRegionDataset(Dataset):\n",
        "    def __init__(self, root_dir, midbrain_center, region_size=(64, 64, 64), transform=None, augment=False):\n",
        "        \"\"\"\n",
        "        Dataset for brain region extraction focused on the substantia nigra.\n",
        "\n",
        "        Args:\n",
        "            root_dir: Directory containing 'hc' and 'pd' subdirectories\n",
        "            midbrain_center: Coordinates of the midbrain center (x, y, z)\n",
        "            region_size: Size of the region to extract\n",
        "            transform: Optional transforms to apply\n",
        "            augment: Whether to apply data augmentation\n",
        "        \"\"\"\n",
        "        self.samples = []\n",
        "        self.midbrain_center = midbrain_center\n",
        "        self.region_size = region_size\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "\n",
        "        # For multi-region extraction\n",
        "        self.additional_regions = [\n",
        "            (-3, 0, 0),   # Left shift\n",
        "            (3, 0, 0),    # Right shift\n",
        "            (0, -3, 0),   # Anterior shift\n",
        "            (0, 3, 0),    # Posterior shift\n",
        "            (0, 0, -3),   # Superior shift\n",
        "            (0, 0, 3)     # Inferior shift\n",
        "        ]\n",
        "\n",
        "        hc_folder = os.path.join(root_dir, 'hc')\n",
        "        pd_folder = os.path.join(root_dir, 'pd')\n",
        "\n",
        "        # Check if directories exist\n",
        "        if not os.path.exists(hc_folder) or not os.path.exists(pd_folder):\n",
        "            raise FileNotFoundError(f\"HC or PD folder not found in {root_dir}\")\n",
        "\n",
        "        hc_files = [os.path.join(hc_folder, f) for f in os.listdir(hc_folder) if f.endswith('.npy')]\n",
        "        pd_files = [os.path.join(pd_folder, f) for f in os.listdir(pd_folder) if f.endswith('.npy')]\n",
        "\n",
        "        print(f\"Found {len(hc_files)} healthy control samples and {len(pd_files)} Parkinson's disease samples\")\n",
        "\n",
        "        # Shuffle the samples\n",
        "        self.samples = [(f, 0) for f in hc_files] + [(f, 1) for f in pd_files]\n",
        "        random.shuffle(self.samples)\n",
        "\n",
        "    def extract_midbrain_region(self, volume, center=None, size=None):\n",
        "        \"\"\"\n",
        "        Extract region around substantia nigra from a brain volume.\n",
        "\n",
        "        Args:\n",
        "            volume: 3D numpy array of brain MRI\n",
        "            center: Center coordinates (x, y, z), defaults to self.midbrain_center\n",
        "            size: Size of region to extract (d, h, w), defaults to self.region_size\n",
        "\n",
        "        Returns:\n",
        "            3D numpy array of extracted region\n",
        "        \"\"\"\n",
        "        if center is None:\n",
        "            center = self.midbrain_center\n",
        "        if size is None:\n",
        "            size = self.region_size\n",
        "\n",
        "        x_center, y_center, z_center = center\n",
        "        d, h, w = size\n",
        "\n",
        "        # Ensure center coordinates are within volume boundaries\n",
        "        x_center = min(max(x_center, d//2), volume.shape[0] - d//2)\n",
        "        y_center = min(max(y_center, h//2), volume.shape[1] - h//2)\n",
        "        z_center = min(max(z_center, w//2), volume.shape[2] - w//2)\n",
        "\n",
        "        x_start, y_start, z_start = x_center - d//2, y_center - h//2, z_center - w//2\n",
        "        x_end, y_end, z_end = x_start + d, y_start + h, z_start + w\n",
        "\n",
        "        # Double-check boundaries\n",
        "        x_start, y_start, z_start = max(x_start, 0), max(y_start, 0), max(z_start, 0)\n",
        "        x_end = min(x_end, volume.shape[0])\n",
        "        y_end = min(y_end, volume.shape[1])\n",
        "        z_end = min(z_end, volume.shape[2])\n",
        "\n",
        "        return volume[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "    def apply_augmentation(self, volume):\n",
        "        \"\"\"Apply random augmentations to the volume\"\"\"\n",
        "        # Random flip\n",
        "        if random.random() > 0.5:\n",
        "            volume = np.flip(volume, axis=0).copy()\n",
        "\n",
        "        # Random rotation ±10 degrees around each axis\n",
        "        for axis in range(3):\n",
        "            if random.random() > 0.5:\n",
        "                angle = random.uniform(-10, 10)\n",
        "                volume = scipy.ndimage.rotate(volume, angle, axes=((axis+1)%3, (axis+2)%3),\n",
        "                                            reshape=False, order=1, mode='constant')\n",
        "\n",
        "        # Random brightness adjustment\n",
        "        if random.random() > 0.5:\n",
        "            factor = random.uniform(0.9, 1.1)\n",
        "            volume = volume * factor\n",
        "            volume = np.clip(volume, 0, 1)\n",
        "\n",
        "        # Random gaussian noise\n",
        "        if random.random() > 0.5:\n",
        "            sigma = random.uniform(0.01, 0.03)\n",
        "            noise = np.random.normal(0, sigma, volume.shape)\n",
        "            volume = volume + noise\n",
        "            volume = np.clip(volume, 0, 1)\n",
        "\n",
        "        # Random contrast adjustment\n",
        "        if random.random() > 0.5:\n",
        "            factor = random.uniform(0.9, 1.1)\n",
        "            mean = volume.mean()\n",
        "            volume = (volume - mean) * factor + mean\n",
        "            volume = np.clip(volume, 0, 1)\n",
        "\n",
        "        # Random gamma adjustment\n",
        "        if random.random() > 0.5:\n",
        "            gamma = random.uniform(0.8, 1.2)\n",
        "            volume = np.power(volume, gamma)\n",
        "\n",
        "        return volume\n",
        "\n",
        "    def preprocess_volume(self, volume):\n",
        "        \"\"\"Preprocess the volume\"\"\"\n",
        "        # Check dimensions\n",
        "        if volume.ndim == 4 and volume.shape[0] == 1:\n",
        "            volume = volume.squeeze(0)  # Remove batch dimension if present\n",
        "        elif volume.ndim > 3:\n",
        "            raise ValueError(f\"Unexpected volume shape: {volume.shape}\")\n",
        "\n",
        "        # Extract region around substantia nigra\n",
        "        midbrain_region = self.extract_midbrain_region(volume)\n",
        "\n",
        "        # Check if region was extracted properly\n",
        "        if 0 in midbrain_region.shape:\n",
        "            raise ValueError(f\"Extracted region has invalid shape: {midbrain_region.shape}\")\n",
        "\n",
        "        # Resize to consistent dimensions\n",
        "        target_shape = (64, 64, 64)\n",
        "        scale_factors = np.array(target_shape) / np.array(midbrain_region.shape)\n",
        "        resized_region = scipy.ndimage.zoom(midbrain_region, scale_factors, order=1)\n",
        "\n",
        "        # Normalize to [0, 1]\n",
        "        if np.max(resized_region) > np.min(resized_region):\n",
        "            resized_region = (resized_region - np.min(resized_region)) / (np.max(resized_region) - np.min(resized_region))\n",
        "\n",
        "        return resized_region\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            volume = np.load(file_path)\n",
        "\n",
        "            # Preprocess volume\n",
        "            processed_region = self.preprocess_volume(volume)\n",
        "\n",
        "            # Apply data augmentation if specified\n",
        "            if self.augment:\n",
        "                processed_region = self.apply_augmentation(processed_region)\n",
        "\n",
        "            # Convert to tensor with channel dimension\n",
        "            processed_tensor = torch.tensor(processed_region, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            if self.transform:\n",
        "                processed_tensor = self.transform(processed_tensor)\n",
        "\n",
        "            return processed_tensor, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {file_path}: {str(e)}\")\n",
        "            placeholder = torch.zeros((1, 64, 64, 64), dtype=torch.float32)\n",
        "            return placeholder, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class CustomResNet3D(nn.Module):\n",
        "    \"\"\"Custom 3D ResNet model for brain MRI classification\"\"\"\n",
        "    def __init__(self, pretrained=True, num_classes=2):\n",
        "        super(CustomResNet3D, self).__init__()\n",
        "\n",
        "        # Start with pretrained R3D_18 model\n",
        "        base_model = models.video.r3d_18(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        base_model.stem[0] = nn.Conv3d(\n",
        "            1,\n",
        "            base_model.stem[0].out_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Remove the final fc layer\n",
        "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
        "\n",
        "        # Create a new fully connected layer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feature extraction\n",
        "        x = self.features(x)\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Classification\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class SELayer3D(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation attention block for 3D data\"\"\"\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SELayer3D, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "\n",
        "class SelfAdaptiveBlock(nn.Module):\n",
        "    \"\"\"Self-adaptive block with dynamic filter adjustment\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, reduction=16):\n",
        "        super(SelfAdaptiveBlock, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size,\n",
        "                           stride=stride, padding=kernel_size//2, bias=False)\n",
        "        self.bn = nn.BatchNorm3d(out_channels)\n",
        "        self.se = SELayer3D(out_channels, reduction)\n",
        "\n",
        "        # Adaptive parameters layer\n",
        "        self.adaptive_params = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),\n",
        "            nn.Conv3d(in_channels, out_channels, 1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Generate adaptive parameters based on input\n",
        "        params = self.adaptive_params(x)\n",
        "\n",
        "        # Apply convolution\n",
        "        out = self.conv(x)\n",
        "\n",
        "        # Apply batch normalization\n",
        "        out = self.bn(out)\n",
        "\n",
        "        # Dynamic scale the features using adaptive parameters\n",
        "        out = out * params\n",
        "\n",
        "        # Apply squeeze-excitation attention\n",
        "        out = self.se(out)\n",
        "\n",
        "        # Apply activation\n",
        "        out = F.relu(out, inplace=True)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class SelfAdaptiveCNN(nn.Module):\n",
        "    \"\"\"Self-adaptive CNN model for 3D brain MRI classification\"\"\"\n",
        "    def __init__(self, in_channels=1, num_classes=2, base_filters=32):\n",
        "        super(SelfAdaptiveCNN, self).__init__()\n",
        "\n",
        "        self.input_conv = nn.Conv3d(in_channels, base_filters, kernel_size=7,\n",
        "                                   stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(base_filters)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Self-adaptive blocks\n",
        "        self.sa_block1 = SelfAdaptiveBlock(base_filters, base_filters*2)\n",
        "        self.sa_block2 = SelfAdaptiveBlock(base_filters*2, base_filters*4, stride=2)\n",
        "        self.sa_block3 = SelfAdaptiveBlock(base_filters*4, base_filters*8, stride=2)\n",
        "        self.sa_block4 = SelfAdaptiveBlock(base_filters*8, base_filters*16, stride=2)\n",
        "\n",
        "        # Global attention pooling\n",
        "        self.gap = nn.AdaptiveAvgPool3d(1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(base_filters*16, 512)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial convolution\n",
        "        x = self.input_conv(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Self-adaptive blocks\n",
        "        x = self.sa_block1(x)\n",
        "        x = self.sa_block2(x)\n",
        "        x = self.sa_block3(x)\n",
        "        x = self.sa_block4(x)\n",
        "\n",
        "        # Global pooling\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AutoAdaptCNNClassifier(nn.Module):\n",
        "    \"\"\"Advanced model combining ResNet3D backbone with self-adaptive mechanisms\"\"\"\n",
        "    def __init__(self, pretrained=True, num_classes=2):\n",
        "        super(AutoAdaptCNNClassifier, self).__init__()\n",
        "\n",
        "        # Start with pretrained R3D_18 model\n",
        "        base_model = models.video.r3d_18(pretrained=pretrained)\n",
        "\n",
        "        # Modify first conv layer to accept single-channel input\n",
        "        base_model.stem[0] = nn.Conv3d(\n",
        "            1,\n",
        "            base_model.stem[0].out_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "        # Remove the final fc layer\n",
        "        self.backbone = nn.Sequential(*list(base_model.children())[:-1])\n",
        "\n",
        "        # Add self-adaptive blocks to enhance feature extraction\n",
        "        self.sa_layer1 = SELayer3D(64, reduction=8)\n",
        "        self.sa_layer2 = SELayer3D(128, reduction=16)\n",
        "        self.sa_layer3 = SELayer3D(256, reduction=16)\n",
        "        self.sa_layer4 = SELayer3D(512, reduction=16)\n",
        "\n",
        "        # Adaptive pooling\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool3d(1)\n",
        "\n",
        "        # Feature dimension after backbone and pooling\n",
        "        self.feature_dim = 512\n",
        "\n",
        "        # Classifier head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # For adaptive learning rate scaling\n",
        "        self.confidence_estimator = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        features = []\n",
        "\n",
        "        # Extract features from backbone while applying attention at each layer\n",
        "        x = self.backbone[0](x)  # stem\n",
        "\n",
        "        x = self.backbone[1](x)  # layer1\n",
        "        x = self.sa_layer1(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.backbone[2](x)  # layer2\n",
        "        x = self.sa_layer2(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.backbone[3](x)  # layer3\n",
        "        x = self.sa_layer3(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.backbone[4](x)  # layer4\n",
        "        x = self.sa_layer4(x)\n",
        "        features.append(x)\n",
        "\n",
        "        x = self.backbone[5](x)  # avg_pool\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        return x, features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        x, _ = self.extract_features(x)\n",
        "\n",
        "        # Get confidence score\n",
        "        confidence = self.confidence_estimator(x)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits, confidence\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, adaptive_learning=True):\n",
        "    \"\"\"Run one training epoch with self-adaptive learning rate scaling\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "\n",
        "    for inputs, labels in progress_bar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        if adaptive_learning:\n",
        "            outputs, confidence = model(inputs)\n",
        "\n",
        "            # Adaptive loss weighting based on confidence\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scale loss inversely with confidence for hard samples\n",
        "            confidence_factor = 1.0 - 0.5 * confidence.mean()\n",
        "            loss = loss * confidence_factor\n",
        "        else:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to prevent exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, preds = torch.max(outputs if isinstance(outputs, torch.Tensor) else outputs[0], 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'acc': f\"{100 * correct / total:.2f}%\"\n",
        "        })\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            if isinstance(model, AutoAdaptCNNClassifier):\n",
        "                outputs, _ = model(inputs)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Save predictions and labels for metrics\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    return running_loss / total, correct / total, np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
        "\n",
        "\n",
        "def create_dataloaders(dataset, train_idx, val_idx, batch_size, balance_classes=True):\n",
        "    \"\"\"Create balanced data loaders for training and validation\"\"\"\n",
        "    train_subset = Subset(dataset, train_idx)\n",
        "    val_subset = Subset(dataset, val_idx)\n",
        "\n",
        "    # Balance classes for training if requested\n",
        "    if balance_classes:\n",
        "        # Get labels for training subset\n",
        "        train_labels = [dataset.samples[i][1] for i in train_idx]\n",
        "        class_counts = np.bincount(train_labels)\n",
        "        class_weights = 1.0 / class_counts\n",
        "\n",
        "        # Assign weights to each sample\n",
        "        sample_weights = [class_weights[label] for label in train_labels]\n",
        "        sample_weights = torch.DoubleTensor(sample_weights)\n",
        "\n",
        "        # Create weighted sampler\n",
        "        sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(train_subset),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_subset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    else:\n",
        "        train_loader = DataLoader(\n",
        "            train_subset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "def k_fold_train_and_validate(dataset, k=5, num_epochs=40, batch_size=8,\n",
        "                             learning_rate=1e-4, weight_decay=2e-4, patience=8,\n",
        "                             model_type=\"auto_adapt\"):\n",
        "    \"\"\"\n",
        "    Train and validate using k-fold cross validation with improved handling.\n",
        "\n",
        "    Args:\n",
        "        dataset: BrainRegionDataset instance\n",
        "        k: Number of folds\n",
        "        num_epochs: Maximum number of training epochs\n",
        "        batch_size: Batch size for training\n",
        "        learning_rate: Initial learning rate\n",
        "        weight_decay: L2 regularization strength\n",
        "        patience: Early stopping patience\n",
        "        model_type: Type of model to use (\"auto_adapt\", \"self_adaptive\", or \"resnet3d\")\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of results for each fold\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Extract labels for stratified splitting\n",
        "    labels = [label for _, label in dataset.samples]\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store results\n",
        "    results = {\n",
        "        'train_losses': [],\n",
        "        'train_accs': [],\n",
        "        'val_losses': [],\n",
        "        'val_accs': [],\n",
        "        'best_models': [],\n",
        "        'fold_metrics': []\n",
        "    }\n",
        "\n",
        "    # Class weights for imbalanced data\n",
        "    class_counts = np.bincount(labels)\n",
        "    class_weights = torch.tensor(len(labels) / (len(class_counts) * class_counts), dtype=torch.float32)\n",
        "\n",
        "    # Train and validate for each fold\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n",
        "        print(f\"\\n{'='*40}\\nTraining Fold {fold+1}/{k}\\n{'='*40}\")\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader, val_loader = create_dataloaders(\n",
        "            dataset, train_idx, val_idx, batch_size, balance_classes=True\n",
        "        )\n",
        "\n",
        "        # Initialize model based on type\n",
        "        if model_type == \"auto_adapt\":\n",
        "            model = AutoAdaptCNNClassifier(pretrained=True).to(device)\n",
        "            adaptive_learning = True\n",
        "        elif model_type == \"self_adaptive\":\n",
        "            model = SelfAdaptiveCNN(in_channels=1, num_classes=2).to(device)\n",
        "            adaptive_learning = True\n",
        "        else:  # resnet3d\n",
        "            model = CustomResNet3D(pretrained=True).to(device)\n",
        "            adaptive_learning = False\n",
        "\n",
        "        # Optimizer with weight decay\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=5, T_mult=2, eta_min=learning_rate/10\n",
        "        )\n",
        "\n",
        "        # Use weighted loss for imbalanced data\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "        # Track best model and metrics\n",
        "        best_val_loss = float('inf')\n",
        "        early_stop_counter = 0\n",
        "        best_model_wts = None\n",
        "        best_epoch = 0\n",
        "\n",
        "        # Training history\n",
        "        fold_train_losses = []\n",
        "        fold_train_accs = []\n",
        "        fold_val_losses = []\n",
        "        fold_val_accs = []\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            # Train\n",
        "            start_time = time.time()\n",
        "            train_loss, train_acc = train_epoch(\n",
        "                model, train_loader, criterion, optimizer, device, adaptive_learning\n",
        "            )\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            fold_train_losses.append(train_loss)\n",
        "            fold_train_accs.append(train_acc)\n",
        "\n",
        "            # Validate\n",
        "            val_loss, val_acc, val_preds, val_labels, val_probs = validate(\n",
        "                model, val_loader, criterion, device\n",
        "            )\n",
        "            fold_val_losses.append(val_loss)\n",
        "            fold_val_accs.append(val_acc)\n",
        "\n",
        "            # Update learning rate\n",
        "            scheduler.step()\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Print metrics\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] | \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | \"\n",
        "                  f\"Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}% | \"\n",
        "                  f\"LR: {current_lr:.6f} | \"\n",
        "                  f\"Time: {train_time:.1f}s\")\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if val_loss < best_val_loss:\n",
        "                print(f\"Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}\")\n",
        "                best_val_loss = val_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                best_epoch = epoch\n",
        "                early_stop_counter = 0\n",
        "            else:\n",
        "                early_stop_counter += 1\n",
        "                print(f\"Validation loss did not improve. Early stopping counter: {early_stop_counter}/{patience}\")\n",
        "                if early_stop_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "        # Load best model weights\n",
        "        model.load_state_dict(best_model_wts)\n",
        "\n",
        "        # Final validation with best model\n",
        "        final_val_loss, final_val_acc, final_preds, final_labels, final_probs = validate(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "        print(f\"\\nFinal validation - Loss: {final_val_loss:.4f}, Acc: {final_val_acc*100:.2f}%\")\n",
        "        print(f\"Best model was from epoch {best_epoch+1}\")\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "        conf_matrix = confusion_matrix(final_labels, final_preds)\n",
        "\n",
        "        # Calculate sensitivity and specificity\n",
        "        tn, fp, fn, tp = conf_matrix.ravel()\n",
        "        sensitivity = tp / (tp + fn)\n",
        "        specificity = tn / (tn + fp)\n",
        "\n",
        "        # Calculate AUC\n",
        "        if final_probs.shape[1] > 1:  # Use probability of positive class\n",
        "            auc = roc_auc_score(final_labels, final_probs[:, 1])\n",
        "        else:\n",
        "            auc = roc_auc_score(final_labels, final_probs)\n",
        "\n",
        "        print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}, AUC: {auc:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(final_labels, final_preds))\n",
        "\n",
        "        # Store fold metrics\n",
        "        fold_metrics = {\n",
        "            'fold': fold,\n",
        "            'val_acc': final_val_acc,\n",
        "            'val_loss': final_val_loss,\n",
        "            'sensitivity': sensitivity,\n",
        "            'specificity': specificity,\n",
        "            'auc': auc,\n",
        "            'conf_matrix': conf_matrix,\n",
        "            'best_epoch': best_epoch\n",
        "        }\n",
        "\n",
        "        # Save fold results\n",
        "        results['train_losses'].append(fold_train_losses)\n",
        "        results['train_accs'].append(fold_train_accs)\n",
        "        results['val_losses'].append(fold_val_losses)\n",
        "        results['val_accs'].append(fold_val_accs)\n",
        "        results['best_models'].append(model.state_dict().copy())\n",
        "        results['fold_metrics'].append(fold_metrics)\n",
        "\n",
        "        # Save model for this fold\n",
        "        torch.save({\n",
        "            'fold': fold,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'val_acc': final_val_acc,\n",
        "            'val_loss': final_val_loss,\n",
        "            'metrics': fold_metrics\n",
        "        }, f'best_model_improved_fold_{fold}.pth')\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_val_acc = np.mean([metrics['val_acc'] for metrics in results['fold_metrics']])\n",
        "    avg_auc = np.mean([metrics['auc'] for metrics in results['fold_metrics']])\n",
        "    avg_sensitivity = np.mean([metrics['sensitivity'] for metrics in results['fold_metrics']])\n",
        "    avg_specificity = np.mean([metrics['specificity'] for metrics in results['fold_metrics']])\n",
        "\n",
        "    print(f\"\\n{'='*40}\\nAverage metrics across {k} folds:\\n{'='*40}\")\n",
        "    print(f\"Accuracy: {avg_val_acc*100:.2f}%\")\n",
        "    print(f\"AUC: {avg_auc:.4f}\")\n",
        "    print(f\"Sensitivity: {avg_sensitivity:.4f}\")\n",
        "    print(f\"Specificity: {avg_specificity:.4f}\")\n",
        "\n",
        "    # Find best fold based on validation accuracy\n",
        "    best_fold_idx = np.argmax([metrics['val_acc'] for metrics in results['fold_metrics']])\n",
        "    best_fold = results['fold_metrics'][best_fold_idx]\n",
        "\n",
        "    print(f\"\\nBest fold: {best_fold['fold']+1} with validation accuracy: {best_fold['val_acc']*100:.2f}%\")\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Plot training & validation loss\n",
        "    plt.subplot(2, 1, 1)\n",
        "    for fold in range(k):\n",
        "        plt.plot(results['train_losses'][fold], label=f'Fold {fold+1} Train')\n",
        "        plt.plot(results['val_losses'][fold], label=f'Fold {fold+1} Val', linestyle='--')\n",
        "    plt.title('Loss per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot training & validation accuracy\n",
        "    plt.subplot(2, 1, 2)\n",
        "    for fold in range(k):\n",
        "        plt.plot(np.array(results['train_accs'][fold]) * 100, label=f'Fold {fold+1} Train')\n",
        "        plt.plot(np.array(results['val_accs'][fold]) * 100, label=f'Fold {fold+1} Val', linestyle='--')\n",
        "    plt.title('Accuracy per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save({\n",
        "        'fold': best_fold['fold'],\n",
        "        'model_state_dict': results['best_models'][best_fold['fold']],\n",
        "        'val_acc': best_fold['val_acc'],\n",
        "        'val_loss': best_fold['val_loss'],\n",
        "        'metrics': best_fold\n",
        "    }, 'best_model_overall.pth')\n",
        "\n",
        "    return results\n",
        "def main():\n",
        "    \"\"\"Main function to run the training and evaluation process\"\"\"\n",
        "    # Set fixed random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    # Define data directory and parameters\n",
        "    data_root = \"/content/drive/MyDrive/3D_Numpy_Volumes\"  # Update this path to your data location\n",
        "\n",
        "    # Define midbrain center coordinates (these would be determined based on your specific dataset)\n",
        "    # These coordinates should point to the substantia nigra region\n",
        "    midbrain_center = (91, 109, 91)  # Example coordinates, adjust based on your data\n",
        "\n",
        "    # Create dataset\n",
        "    print(\"Creating dataset...\")\n",
        "    try:\n",
        "        dataset = BrainRegionDataset(\n",
        "            root_dir=data_root,\n",
        "            midbrain_center=midbrain_center,\n",
        "            region_size=(64, 64, 64),\n",
        "            augment=True  # Enable data augmentation for training\n",
        "        )\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please make sure the data directory exists with 'hc' and 'pd' subdirectories.\")\n",
        "        return\n",
        "\n",
        "    # Set training parameters\n",
        "    params = {\n",
        "        'k': 5,                  # Number of folds\n",
        "        'num_epochs': 50,        # Maximum number of epochs\n",
        "        'batch_size': 8,         # Batch size\n",
        "        'learning_rate': 1e-4,   # Initial learning rate\n",
        "        'weight_decay': 2e-4,    # Weight decay for regularization\n",
        "        'patience': 8,           # Early stopping patience\n",
        "        'model_type': \"auto_adapt\"  # Model type (options: \"auto_adapt\", \"self_adaptive\", \"resnet3d\")\n",
        "    }\n",
        "\n",
        "    # Run k-fold cross-validation\n",
        "    print(f\"Starting {params['k']}-fold cross-validation with {params['model_type']} model...\")\n",
        "    results = k_fold_train_and_validate(dataset, **params)\n",
        "\n",
        "    # These variables are calculated in k_fold_train_and_validate and returned in results\n",
        "    avg_val_acc = np.mean([metrics['val_acc'] for metrics in results['fold_metrics']])\n",
        "    avg_auc = np.mean([metrics['auc'] for metrics in results['fold_metrics']])\n",
        "    avg_sensitivity = np.mean([metrics['sensitivity'] for metrics in results['fold_metrics']])\n",
        "    avg_specificity = np.mean([metrics['specificity'] for metrics in results['fold_metrics']])\n",
        "\n",
        "    print(f\"\\n{'='*40}\\nOverall Results\\n{'='*40}\")\n",
        "    print(f\"Average validation accuracy: {avg_val_acc*100:.2f}%\")\n",
        "    print(f\"Average AUC: {avg_auc:.4f}\")\n",
        "    print(f\"Average sensitivity: {avg_sensitivity:.4f}\")\n",
        "    print(f\"Average specificity: {avg_specificity:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    torch.save(results, 'training_results.pth')\n",
        "\n",
        "    # Load best model for inference\n",
        "    print(\"Loading best model for inference...\")\n",
        "    best_model_data = torch.load('best_model_overall.pth')\n",
        "    best_fold = best_model_data['fold']\n",
        "\n",
        "    # Initialize the model with the same architecture\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if params['model_type'] == \"auto_adapt\":\n",
        "        model = AutoAdaptCNNClassifier(pretrained=False).to(device)\n",
        "    elif params['model_type'] == \"self_adaptive\":\n",
        "        model = SelfAdaptiveCNN(in_channels=1, num_classes=2).to(device)\n",
        "    else:  # resnet3d\n",
        "        model = CustomResNet3D(pretrained=False).to(device)\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_data['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Best model loaded from fold {best_fold+1} with validation accuracy: {best_model_data['val_acc']*100:.2f}%\")\n",
        "\n",
        "    # Example of how to use the model for inference\n",
        "    def predict_sample(model, sample_path, midbrain_center, device):\n",
        "        \"\"\"Make prediction on a single sample\"\"\"\n",
        "        try:\n",
        "            # Load the volume\n",
        "            volume = np.load(sample_path)\n",
        "\n",
        "            # Create a temporary dataset with same preprocessing\n",
        "            temp_dataset = BrainRegionDataset(\n",
        "                root_dir=\"./\",  # Not used here\n",
        "                midbrain_center=midbrain_center,\n",
        "                region_size=(64, 64, 64),\n",
        "                augment=False\n",
        "            )\n",
        "\n",
        "            # Preprocess the volume\n",
        "            processed_region = temp_dataset.preprocess_volume(volume)\n",
        "            processed_tensor = torch.tensor(processed_region, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "            processed_tensor = processed_tensor.to(device)\n",
        "\n",
        "            # Make prediction\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, AutoAdaptCNNClassifier):\n",
        "                    outputs, confidence = model(processed_tensor)\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    return predicted.item(), probabilities[0, 1].item(), confidence.item()\n",
        "                else:\n",
        "                    outputs = model(processed_tensor)\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    return predicted.item(), probabilities[0, 1].item(), None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {str(e)}\")\n",
        "            return None, None, None\n",
        "\n",
        "    # Example test for visualization (if you have test samples)\n",
        "    print(\"\\nTesting model on example cases:\")\n",
        "    test_samples = [\n",
        "        # Add paths to test samples here\n",
        "        # (\"/content/drive/MyDrive/3D_Numpy_Volumes/hc/hc_subject13.npy\", \"HC\"),\n",
        "        # (\"/content/drive/MyDrive/3D_Numpy_Volumes/pd/pd_subject13.npy\", \"PD\")\n",
        "    ]\n",
        "\n",
        "    for sample_path, true_label in test_samples:\n",
        "        pred_class, prob, conf = predict_sample(model, sample_path, midbrain_center, device)\n",
        "\n",
        "        if pred_class is not None:\n",
        "            pred_label = \"PD\" if pred_class == 1 else \"HC\"\n",
        "            print(f\"Sample: {sample_path}\")\n",
        "            print(f\"True label: {true_label}, Predicted: {pred_label}\")\n",
        "            print(f\"Probability of PD: {prob:.4f}\")\n",
        "            if conf is not None:\n",
        "                print(f\"Model confidence: {conf:.4f}\")\n",
        "            print(\"---\")\n",
        "\n",
        "    print(\"Training and evaluation completed successfully!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftD_xKEsBcIy",
        "outputId": "2609111a-9cf3-4f16-b54e-72daa1c25d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset...\n",
            "Found 49 healthy control samples and 49 Parkinson's disease samples\n",
            "Starting 5-fold cross-validation with auto_adapt model...\n",
            "Using device: cpu\n",
            "\n",
            "========================================\n",
            "Training Fold 1/5\n",
            "========================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Training: 100%|██████████| 10/10 [05:16<00:00, 31.64s/it, loss=0.4919, acc=55.13%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] | Train Loss: 0.5098, Acc: 55.13% | Val Loss: 0.6947, Acc: 50.00% | LR: 0.000091 | Time: 316.4s\n",
            "Validation loss improved from inf to 0.6947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  60%|██████    | 6/10 [03:16<02:03, 30.75s/it, loss=0.5152, acc=50.00%]"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the training and evaluation process\"\"\"\n",
        "    # Set fixed random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    # Define data directory and parameters\n",
        "    data_root = \"/content/drive/MyDrive/3D_Numpy_Volumes\"  # Update this path to your data location\n",
        "\n",
        "    # Define midbrain center coordinates (these would be determined based on your specific dataset)\n",
        "    # These coordinates should point to the substantia nigra region\n",
        "    midbrain_center = (91, 109, 91)  # Example coordinates, adjust based on your data\n",
        "\n",
        "    # Create dataset\n",
        "    print(\"Creating dataset...\")\n",
        "    try:\n",
        "        dataset = BrainRegionDataset(\n",
        "            root_dir=data_root,\n",
        "            midbrain_center=midbrain_center,\n",
        "            region_size=(64, 64, 64),\n",
        "            augment=True  # Enable data augmentation for training\n",
        "        )\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please make sure the data directory exists with 'hc' and 'pd' subdirectories.\")\n",
        "        return\n",
        "\n",
        "    # Set training parameters\n",
        "    params = {\n",
        "        'k': 5,                  # Number of folds\n",
        "        'num_epochs': 50,        # Maximum number of epochs\n",
        "        'batch_size': 8,         # Batch size\n",
        "        'learning_rate': 1e-4,   # Initial learning rate\n",
        "        'weight_decay': 2e-4,    # Weight decay for regularization\n",
        "        'patience': 8,           # Early stopping patience\n",
        "        'model_type': \"auto_adapt\"  # Model type (options: \"auto_adapt\", \"self_adaptive\", \"resnet3d\")\n",
        "    }\n",
        "\n",
        "    # Run k-fold cross-validation\n",
        "    print(f\"Starting {params['k']}-fold cross-validation with {params['model_type']} model...\")\n",
        "    results = k_fold_train_and_validate(dataset, **params)\n",
        "\n",
        "    # These variables are calculated in k_fold_train_and_validate and returned in results\n",
        "    avg_val_acc = np.mean([metrics['val_acc'] for metrics in results['fold_metrics']])\n",
        "    avg_auc = np.mean([metrics['auc'] for metrics in results['fold_metrics']])\n",
        "    avg_sensitivity = np.mean([metrics['sensitivity'] for metrics in results['fold_metrics']])\n",
        "    avg_specificity = np.mean([metrics['specificity'] for metrics in results['fold_metrics']])\n",
        "\n",
        "    print(f\"\\n{'='*40}\\nOverall Results\\n{'='*40}\")\n",
        "    print(f\"Average validation accuracy: {avg_val_acc*100:.2f}%\")\n",
        "    print(f\"Average AUC: {avg_auc:.4f}\")\n",
        "    print(f\"Average sensitivity: {avg_sensitivity:.4f}\")\n",
        "    print(f\"Average specificity: {avg_specificity:.4f}\")\n",
        "\n",
        "    # Save results\n",
        "    torch.save(results, 'training_results.pth')\n",
        "\n",
        "    # Load best model for inference\n",
        "    print(\"Loading best model for inference...\")\n",
        "    best_model_data = torch.load('best_model_overall.pth')\n",
        "    best_fold = best_model_data['fold']\n",
        "\n",
        "    # Initialize the model with the same architecture\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if params['model_type'] == \"auto_adapt\":\n",
        "        model = AutoAdaptCNNClassifier(pretrained=False).to(device)\n",
        "    elif params['model_type'] == \"self_adaptive\":\n",
        "        model = SelfAdaptiveCNN(in_channels=1, num_classes=2).to(device)\n",
        "    else:  # resnet3d\n",
        "        model = CustomResNet3D(pretrained=False).to(device)\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_data['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Best model loaded from fold {best_fold+1} with validation accuracy: {best_model_data['val_acc']*100:.2f}%\")\n",
        "\n",
        "    # Example of how to use the model for inference\n",
        "    def predict_sample(model, sample_path, midbrain_center, device):\n",
        "        \"\"\"Make prediction on a single sample\"\"\"\n",
        "        try:\n",
        "            # Load the volume\n",
        "            volume = np.load(sample_path)\n",
        "\n",
        "            # Create a temporary dataset with same preprocessing\n",
        "            temp_dataset = BrainRegionDataset(\n",
        "                root_dir=\"./\",  # Not used here\n",
        "                midbrain_center=midbrain_center,\n",
        "                region_size=(64, 64, 64),\n",
        "                augment=False\n",
        "            )\n",
        "\n",
        "            # Preprocess the volume\n",
        "            processed_region = temp_dataset.preprocess_volume(volume)\n",
        "            processed_tensor = torch.tensor(processed_region, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "            processed_tensor = processed_tensor.to(device)\n",
        "\n",
        "            # Make prediction\n",
        "            with torch.no_grad():\n",
        "                if isinstance(model, AutoAdaptCNNClassifier):\n",
        "                    outputs, confidence = model(processed_tensor)\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    return predicted.item(), probabilities[0, 1].item(), confidence.item()\n",
        "                else:\n",
        "                    outputs = model(processed_tensor)\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    return predicted.item(), probabilities[0, 1].item(), None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {str(e)}\")\n",
        "            return None, None, None\n",
        "\n",
        "    # Example test for visualization (if you have test samples)\n",
        "    print(\"\\nTesting model on example cases:\")\n",
        "    test_samples = [\n",
        "        # Add paths to test samples here\n",
        "        # (\"/content/drive/MyDrive/3D_Numpy_Volumes/hc/hc_subject13.npy\", \"HC\"),\n",
        "        # (\"/content/drive/MyDrive/3D_Numpy_Volumes/pd/pd_subject13.npy\", \"PD\")\n",
        "    ]\n",
        "\n",
        "    for sample_path, true_label in test_samples:\n",
        "        pred_class, prob, conf = predict_sample(model, sample_path, midbrain_center, device)\n",
        "\n",
        "        if pred_class is not None:\n",
        "            pred_label = \"PD\" if pred_class == 1 else \"HC\"\n",
        "            print(f\"Sample: {sample_path}\")\n",
        "            print(f\"True label: {true_label}, Predicted: {pred_label}\")\n",
        "            print(f\"Probability of PD: {prob:.4f}\")\n",
        "            if conf is not None:\n",
        "                print(f\"Model confidence: {conf:.4f}\")\n",
        "            print(\"---\")\n",
        "\n",
        "    print(\"Training and evaluation completed successfully!\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgn8Kp08962y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "def train(model, train_dataset, val_dataset, batch_size=16, num_epochs=50, learning_rate=5e-5, device='cuda'):\n",
        "    \"\"\"\n",
        "    Train the 3D ResNet model on the provided training and validation datasets.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        train_dataset: The training dataset.\n",
        "        val_dataset: The validation dataset.\n",
        "        batch_size: The batch size.\n",
        "        num_epochs: The number of training epochs.\n",
        "        learning_rate: The learning rate.\n",
        "        device: The device to use ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        The trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Tracking metrics\n",
        "    best_val_acc = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        correct_preds = 0\n",
        "        total_preds = 0\n",
        "\n",
        "        # Training phase\n",
        "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_preds += torch.sum(preds == labels.data)\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "        # Calculate training accuracy and loss\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct_preds.double() / total_preds\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        val_loss = 0.0\n",
        "        val_correct_preds = 0\n",
        "        val_total_preds = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Calculate accuracy\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct_preds += torch.sum(preds == labels.data)\n",
        "                val_total_preds += labels.size(0)\n",
        "\n",
        "        # Calculate validation accuracy and loss\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_acc = val_correct_preds.double() / val_total_preds\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Load the best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(f\"Training complete. Best validation accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "# train(model, train_dataset, val_dataset, batch_size=16, num_epochs=50, learning_rate=1e-4, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "JP3GBjqc0sU5",
        "outputId": "83db7c60-34c2-4c7c-81a2-fe9d808f0556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "Overall Results\n",
            "========================================\n",
            "Found 49 healthy control samples and 49 Parkinson's disease samples\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'avg_val_acc' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6cf719f5fa61>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-6cf719f5fa61>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Create dataset with augmentation for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     dataset = BrainRegionDataset(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmidbrain_center\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubstantia_nigra_center\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-70230d56212f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, midbrain_center, region_size, transform, augment)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n{'='*40}\\nOverall Results\\n{'='*40}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(hc_files)} healthy control samples and {len(pd_files)} Parkinson's disease samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average validation accuracy: {avg_val_acc*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average AUC: {avg_auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Average sensitivity: {avg_sensitivity:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg_val_acc' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# # Import your modules\n",
        "# from improved_model import(\n",
        "#     BrainRegionDataset,\n",
        "#     AutoAdaptCNNClassifier,\n",
        "#     SelfAdaptiveCNN,\n",
        "#     CustomResNet3D,\n",
        "# )\n",
        "\n",
        "def main():\n",
        "    # Set data directory and substantia nigra center coordinates\n",
        "    data_dir = '/content/drive/MyDrive/3D_Numpy_Volumes'  # Update this to your data path\n",
        "\n",
        "    # These should be the coordinates of the substantia nigra in your dataset\n",
        "    # You might need to adjust these based on your specific dataset\n",
        "    substantia_nigra_center = (85, 130, 110)  # Example coordinates (x, y, z)\n",
        "    region_size = (64, 64, 64)  # Size of region to extract\n",
        "\n",
        "    # Create dataset with augmentation for training\n",
        "    dataset = BrainRegionDataset(\n",
        "        root_dir=data_dir,\n",
        "        midbrain_center=substantia_nigra_center,\n",
        "        region_size=region_size,\n",
        "        augment=True  # Enable data augmentation\n",
        "    )\n",
        "\n",
        "    # Set improved training parameters\n",
        "    params = {\n",
        "        'k': 5,\n",
        "        'num_epochs': 50,\n",
        "        'batch_size': 8,\n",
        "        'learning_rate': 5e-5,\n",
        "        'weight_decay': 2e-4,\n",
        "        'patience': 8,\n",
        "        'model_type': \"auto_adapt\"  # Use the self-adaptive model\n",
        "    }\n",
        "\n",
        "    # Print dataset information\n",
        "    print(f\"Dataset size: {len(dataset)}\")\n",
        "    print(f\"Sample shape: {dataset[0][0].shape}\")\n",
        "\n",
        "    # Print model architecture\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = AutoAdaptCNNClassifier(pretrained=True).to(device)\n",
        "    sample_input = torch.zeros((1, 1, 64, 64, 64)).to(device)\n",
        "    _ = model(sample_input)  # Forward pass to initialize\n",
        "\n",
        "    # Print model parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "    # Load a pre-trained model if available\n",
        "    try:\n",
        "        checkpoint = torch.load('best_model_improved_fold_0.pth', map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        print(f\"Loaded pre-trained model with validation accuracy: {checkpoint['val_acc']*100:.2f}%\")\n",
        "\n",
        "        # Make predictions on a few samples\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i in range(min(5, len(dataset))):\n",
        "                sample, label = dataset[i]\n",
        "                sample = sample.unsqueeze(0).to(device)\n",
        "                output, confidence = model(sample)\n",
        "                pred = torch.argmax(output, dim=1).item()\n",
        "                conf_score = confidence.item()\n",
        "\n",
        "                class_names = [\"Healthy Control\", \"Parkinson's Disease\"]\n",
        "                print(f\"Sample {i}: True: {class_names[label.item()]}, \"\n",
        "                      f\"Predicted: {class_names[pred]}, Confidence: {conf_score:.4f}\")\n",
        "\n",
        "                if i < 3:  # Visualize first 3 samples\n",
        "                    visualize_region(dataset, idx=i)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"No pre-trained model found. Please train the model first.\")\n",
        "\n",
        "\n",
        "def compare_models(dataset, device=None):\n",
        "    \"\"\"\n",
        "    Compare different model architectures on the same dataset\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Create the models\n",
        "    models = {\n",
        "        \"Self-Adaptive CNN\": AutoAdaptCNNClassifier(pretrained=True).to(device),\n",
        "        \"Simple CNN\": SelfAdaptiveCNN(in_channels=1, num_classes=2).to(device),\n",
        "        \"ResNet3D\": CustomResNet3D(pretrained=True).to(device)\n",
        "    }\n",
        "\n",
        "    # Create a small validation set\n",
        "    from torch.utils.data import random_split\n",
        "    val_size = min(int(len(dataset) * 0.2), 20)  # 20% or max 20 samples\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    # Create validation dataloader\n",
        "    from torch.utils.data import DataLoader\n",
        "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "    # Compare inference speed and memory usage\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Set to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Measure memory usage\n",
        "        start_mem = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n",
        "\n",
        "        # Measure inference time\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                if name == \"Self-Adaptive CNN\":\n",
        "                    outputs, _ = model(inputs)\n",
        "                    probs = torch.softmax(outputs, dim=1)\n",
        "                else:\n",
        "                    outputs = model(inputs)\n",
        "                    probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                if probs.shape[1] > 1:\n",
        "                    all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of class 1\n",
        "                else:\n",
        "                    all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        auc_score = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "        inference_time = time.time() - start_time\n",
        "        mem_used = (torch.cuda.memory_allocated() - start_mem) / 1024**2 if torch.cuda.is_available() else 0\n",
        "\n",
        "        results[name] = {\n",
        "            'accuracy': accuracy,\n",
        "            'auc': auc_score,\n",
        "            'inference_time': inference_time,\n",
        "            'memory_mb': mem_used\n",
        "        }\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nModel Comparison Results:\")\n",
        "    print(f\"{'Model':<20} {'Accuracy':<10} {'AUC':<10} {'Time (s)':<10} {'Memory (MB)':<15}\")\n",
        "    print(\"-\" * 65)\n",
        "    for name, metrics in results.items():\n",
        "        print(f\"{name:<20} {metrics['accuracy']*100:.2f}% {metrics['auc']:.4f} {metrics['inference_time']:.4f}s {metrics['memory_mb']:.2f}\")\n",
        "\n",
        "    # Plot ROC curves\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.eval()\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                if name == \"Self-Adaptive CNN\":\n",
        "                    outputs, _ = model(inputs)\n",
        "                    probs = torch.softmax(outputs, dim=1)\n",
        "                else:\n",
        "                    outputs = model(inputs)\n",
        "                    probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                if probs.shape[1] > 1:\n",
        "                    all_probs.extend(probs[:, 1].cpu().numpy())  # Probability of class 1\n",
        "                else:\n",
        "                    all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "        # Calculate ROC curve\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}